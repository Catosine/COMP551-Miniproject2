{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP551 Mini Project 2 - IMDB Sentiment Analysis  \n",
    "This is the codes of mini project2 - IMDB Sentiment Analysis.  \n",
    "\n",
    "## AUTHORS\n",
    "Pengnan Fan, ID#260768510  \n",
    "\n",
    "## TASKS\n",
    "1. **Bernoulli Naive Bayes** (w/o any external library).  \n",
    "2. **At least 2** out of 3 classifiers from the SciKit. i.e. suggestions: logistic regression, decision tree, or support vector machines  \n",
    "3. **At least 2** different features extraction pipelines for processing the data.  \n",
    "4. A model validation. i.e. **K-fold cross validation**  \n",
    "\n",
    "## UPDATES\n",
    "**<January 6, 2019>** Pengnan Fan create this notebook and implements functions readTrainData and readTestData  \n",
    "> * ~~**readTrainData(address:String):DataFrame**~~  \n",
    "> ~~This function takes a string **address** which indicates the address of your train data and will load comments and isPositive to a DataFrame.~~  \n",
    "> * ~~**readTestData(address:String):DataFrame**~~  \n",
    "> ~~This function takes a string **address** which indicates the address of your test data and will load comments and isPositive to a DataFrame. **Note: all isPositive is initialized as 0**~~  \n",
    "> * **Learning set** 25000 in total\n",
    "> * **Test set** 25000 in total  \n",
    "\n",
    "**<January 7, 2019>** Pengnan Fan implements wordsFrequencyNaive and wordsFrequencyStopword\n",
    "> * **wordsFrequencyNaive(dataSet:DataFrame)**  \n",
    "> This function takes a DataFrame **dataSet** and calculate the naive word frequency  \n",
    "> * **wordsFrequencyStopword(dataSet:DataFrame)**  \n",
    "> This function takes a DataFrame **dataSet** and calculate the word frequency without stopwords  \n",
    "\n",
    "**<January 9, 2019>** Pengnan Fan uses sklearn.datasets.load_files(address:str) to load all datas. It helps to increase the speed of loading. And the implementation of Bernoulli naive Bayes has been started.  \n",
    "> * **sklearn.datasets.load_files** - [Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_files.html)\n",
    "\n",
    "**<January 10, 2019>** Pengnan Fan implements numOfExistanceNaive and numOfExistanceStopword\n",
    "> * **numOfExistanceNaive(dataset:Bunch)**  \n",
    "> This function takes a Bunch **dataSet** and calculate the naive existance of words~~  \n",
    "> * **numOfExistanceStopword(dataset:Bunch)**  \n",
    "> This funciton takes a Bunch **dataSet** and calculate the existance of words without stopwords  \n",
    "\n",
    "**<January 11, 2019>** Pengnan Fan implements bernoulliNaiveBayes and evaluation. Also, the dataset is changed by using loadData  \n",
    "> * ~~**bernoulliNaiveBayes(dataSet:Bunch, totalWordFreq:set, negWordFreq:set, posWordFreq:set, numOfExamples:list)**~~  \n",
    "> ~~This function takes a Bunch **dataSet** as learning set and uses three sets of **totalWordFreq**, **negWordFreq**, **posWordFreq** and a list **numOfExamples** to calculates related probabilities. Note: It is not completely corrent. Fix later today.~~  \n",
    "> ~~* **evaluation(dataSet:Bunch, prediction:list)**  \n",
    "> This function takes a Bunch **dataSet** and a list **prediction** to generate a set containing true pos\\true neg\\false pos\\false neg\n",
    "> * **loadData(address:str)**~~  \n",
    "> This function takes a string **address** and generate a dict of 3 lists (pos, neg, all) of dict ('comment', 'isPos')  \n",
    "\n",
    "**<January 13, 2019>** Pengnan Fan fixs numOfExistanceStopword and bernoulliNaiveBayes\n",
    "> * **advancedNumOfExistance(dataset:dict of list of dict)**  \n",
    "> This funciton takes a dict of list of dict **dataSet** and calculate the existance of words without stopwords, puctuations, and duplicates.  \n",
    "> * **bernoulliNaiveBayes(dataSet:list of dict, wordExistance:dict of list, size:dict of list)**  \n",
    "> This function takes a list of dict **dataSet** as predicting set and uses a dict of list **wordExistance** and a dict of list **size** to calculates related probabilities.  \n",
    "> * **evaluation(dataSet:list of dict, prediction:list)**  \n",
    "> This function takes a list of dict **dataSet** and a list **prediction** to generate a set containing true pos\\true neg\\false pos\\false neg  \n",
    "> * **Outcome** TP =  11848, TN =  11482, FP =  1018, FN =  652  \n",
    ">> accuracy =  93.32 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import sys\n",
    "import math\n",
    "from time import sleep\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "import numpy\n",
    "import scipy\n",
    "import sklearn.datasets\n",
    "import contractions\n",
    "from itertools import groupby\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0 - Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 0.1 - Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading negative set\n",
      "Complete loading negative set\n",
      "Start loading positive set\n",
      "Complete loading postive set\n",
      "Preparing negative set: [=================== ] 99%\n",
      "12500\n",
      "Prepare positive set: [=================== ] 99%\n",
      "Finish preparing\n"
     ]
    }
   ],
   "source": [
    "# Task 0 - Preprocessing Data\n",
    "\n",
    "# Please add your address here as string\n",
    "ADDRESS_TRAIN_PENGNAN = \"D:\\\\McGill\\\\19Fall\\\\COMP 551\\\\Projects\\\\Project2\\\\comp-551-imbd-sentiment-classification\\\\train\"\n",
    "ADDRESS_TEST_PENGNAN = \"D:\\\\McGill\\\\19Fall\\\\COMP 551\\\\Projects\\\\Project2\\\\comp-551-imbd-sentiment-classification\\\\test\"\n",
    "\n",
    "\n",
    "\n",
    "# @author Pengnan Fan\n",
    "# @param address of train set\n",
    "# @return a dict of list of dict\n",
    "def loadData(address):\n",
    "    print(\"Start loading negative set\")\n",
    "    neg = sklearn.datasets.load_files(address, categories={\"neg\"})\n",
    "    print(\"Complete loading negative set\")\n",
    "    print(\"Start loading positive set\")\n",
    "    pos = sklearn.datasets.load_files(address, categories={\"pos\"})\n",
    "    print(\"Complete loading postive set\")\n",
    "    \n",
    "    negSet = list()\n",
    "    count = 0\n",
    "    size = len(neg.data)\n",
    "    for x in neg.data:\n",
    "        negSet.append({\"comment\":x.decode('utf-8'), \"isPos\":0})\n",
    "        \n",
    "        # This is for loading bar\n",
    "        sys.stdout.write('\\r')\n",
    "        c = int((float(count) / float(size)) * 100)\n",
    "        sys.stdout.write(\"Preparing negative set: [%-20s] %d%%\" % ('='*int(c / 5), c))\n",
    "        sleep(0.001)\n",
    "        sys.stdout.flush()\n",
    "        count += 1\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    posSet = list()\n",
    "    count = 0\n",
    "    size = len(pos.data)\n",
    "    print(size)\n",
    "    for x in pos.data:\n",
    "        posSet.append({\"comment\":x.decode('utf-8'), \"isPos\":1})\n",
    "        \n",
    "        # This is for loading bar\n",
    "        sys.stdout.write('\\r')\n",
    "        c = int((float(count) / float(size)) * 100)\n",
    "        sys.stdout.write(\"Prepare positive set: [%-20s] %d%%\" % ('='*int(c / 5), c))\n",
    "        sleep(0.001)\n",
    "        sys.stdout.flush()\n",
    "        count += 1\n",
    "    \n",
    "    output = {'pos':posSet, 'neg':negSet, 'all':posSet+negSet}\n",
    "    print(\"\\nFinish preparing\")\n",
    "    return output\n",
    "\n",
    "# Advanced loader\n",
    "# @return: Bunch\n",
    "\n",
    "trainSet = loadData(ADDRESS_TRAIN_PENGNAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n"
     ]
    }
   ],
   "source": [
    "# An example of the dataset\n",
    "print(len(trainSet['neg']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 0.2 - Naive Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @author Pengnan Fan\n",
    "# @param dataSet: set of comments\n",
    "# @return naiveCount: naive word frequency\n",
    "def wordsFrequencyNaive(dataSet):\n",
    "    naiveCount = dict()\n",
    "    totalComments = []\n",
    "    count = 0\n",
    "    lenW = len(dataSet['pos'])\n",
    "    \n",
    "    print(\"Start counting naive word frequency of positive set\")\n",
    "    for comment in dataSet['pos']:\n",
    "        totalComments+=comment['comment'].lower().split(\" \")\n",
    "        \n",
    "        # This is for loading bar\n",
    "        sys.stdout.write('\\r')\n",
    "        c = int((float(count) / float(lenW)) * 100)\n",
    "        sys.stdout.write(\"[%-20s] %d%%\" % ('='*int(c / 5), c))\n",
    "        sleep(0.001)\n",
    "        sys.stdout.flush()\n",
    "        count += 1\n",
    "        \n",
    "    print(\"\\nComplete counting naive word frequency of positive set\")\n",
    "    \n",
    "    posCount = Counter(x for x in totalComments)\n",
    "    \n",
    "    totalComments = []\n",
    "    count = 0\n",
    "    lenW = len(dataSet['neg'])\n",
    "    \n",
    "    print(\"Start counting naive word frequency of negative set\")\n",
    "    for comment in dataSet['neg']:\n",
    "        totalComments+=comment['comment'].lower().split(\" \")\n",
    "        \n",
    "        # This is for loading bar\n",
    "        sys.stdout.write('\\r')\n",
    "        c = int((float(count) / float(lenW)) * 100)\n",
    "        sys.stdout.write(\"[%-20s] %d%%\" % ('='*int(c / 5), c))\n",
    "        sleep(0.001)\n",
    "        sys.stdout.flush()\n",
    "        count += 1\n",
    "        \n",
    "    print(\"\\nComplete counting naive word frequency of negative set\")\n",
    "    \n",
    "    negCount = Counter(x for x in totalComments)\n",
    "    \n",
    "    totalComments = []\n",
    "    count = 0\n",
    "    lenW = len(dataSet['all'])\n",
    "    \n",
    "    print(\"Start counting naive word frequency of all set\")\n",
    "    for comment in dataSet['all']:\n",
    "        totalComments+=comment['comment'].lower().split(\" \")\n",
    "        \n",
    "        # This is for loading bar\n",
    "        sys.stdout.write('\\r')\n",
    "        c = int((float(count) / float(lenW)) * 100)\n",
    "        sys.stdout.write(\"[%-20s] %d%%\" % ('='*int(c / 5), c))\n",
    "        sleep(0.001)\n",
    "        sys.stdout.flush()\n",
    "        count += 1\n",
    "        \n",
    "    print(\"\\nComplete counting naive word frequency of all set\")\n",
    "    \n",
    "    allCount = Counter(x for x in totalComments)\n",
    "    \n",
    "    naiveCount = {'pos':posCount, 'neg':negCount, 'all':allCount}\n",
    "    return naiveCount\n",
    "\n",
    "\n",
    "# naiveFrequency = wordsFrequencyNaive(trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(naiveFrequency.most_common(160))\\nprint(\"Size of naiveFrequency: \", len(naiveFrequency))\\nprint(\"Example: the = \", naiveFrequency[\\'the\\'])\\nprint(naiveFrequency_neg.most_common(160))\\nprint(\"Size of naiveFrequency_neg: \", len(naiveFrequency_neg))\\nprint(\"Example: the = \", naiveFrequency_neg[\\'the\\'])\\nprint(naiveFrequency_pos.most_common(160))\\nprint(\"Size of naiveFrequency_pos:\", len(naiveFrequency_pos))\\nprint(\"Example: the = \", naiveFrequency_pos[\\'the\\'])\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of naive word frequency\n",
    "'''\n",
    "print(naiveFrequency.most_common(160))\n",
    "print(\"Size of naiveFrequency: \", len(naiveFrequency))\n",
    "print(\"Example: the = \", naiveFrequency['the'])\n",
    "print(naiveFrequency_neg.most_common(160))\n",
    "print(\"Size of naiveFrequency_neg: \", len(naiveFrequency_neg))\n",
    "print(\"Example: the = \", naiveFrequency_neg['the'])\n",
    "print(naiveFrequency_pos.most_common(160))\n",
    "print(\"Size of naiveFrequency_pos:\", len(naiveFrequency_pos))\n",
    "print(\"Example: the = \", naiveFrequency_pos['the'])\n",
    "'''\n",
    "# print(naiveFrequency['all'].most_common(160))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 0.3 - Word Frequency without Stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @author Pengnan Fan\n",
    "# @acknowledgement Yuxiang Ma, for this function is edited based on his in miniproject1\n",
    "# @param dataSet: set of comments\n",
    "# @return naiveCount: word frequency without stopwords\n",
    "def wordsFrequencyStopword(dataSet):\n",
    "    stopwordCount = dict()\n",
    "    totalString = str()\n",
    "    count = 0\n",
    "    lenW = len(dataSet['pos'])\n",
    "    \n",
    "    print(\"Start counting naive word frequency of positive set\")\n",
    "    \n",
    "    for comment in dataSet['pos']:\n",
    "        totalString = totalString + ' ' + comment['comment'].lower()\n",
    "        \n",
    "        # This is for loading bar\n",
    "        sys.stdout.write('\\r')\n",
    "        c = int((float(count) / float(lenW)) * 100)\n",
    "        sys.stdout.write(\"[%-20s] %d%%\" % ('='*int(c / 5), c))\n",
    "        sleep(0.001)\n",
    "        sys.stdout.flush()\n",
    "        count += 1\n",
    "    \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    withoutPunc = tokenizer.tokenize(totalString)\n",
    "    stopwordsSet = set(stopwords.words())\n",
    "    posCountDict = Counter(s.lower() for s in withoutPunc if s.lower() not in stopwordsSet)\n",
    "    print(\"\\nComplete counting naive word frequency of positive set\")\n",
    "    \n",
    "    totalString = str()\n",
    "    count = 0\n",
    "    lenW = len(dataSet['neg'])\n",
    "    \n",
    "    print(\"Start counting naive word frequency of negative set\")\n",
    "    \n",
    "    for comment in dataSet['neg']:\n",
    "        totalString = totalString + ' ' + comment['comment'].lower()\n",
    "        \n",
    "        # This is for loading bar\n",
    "        sys.stdout.write('\\r')\n",
    "        c = int((float(count) / float(lenW)) * 100)\n",
    "        sys.stdout.write(\"[%-20s] %d%%\" % ('='*int(c / 5), c))\n",
    "        sleep(0.001)\n",
    "        sys.stdout.flush()\n",
    "        count += 1\n",
    "    \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    withoutPunc = tokenizer.tokenize(totalString)\n",
    "    stopwordsSet = set(stopwords.words())\n",
    "    negCountDict = Counter(s.lower() for s in withoutPunc if s.lower() not in stopwordsSet)\n",
    "    print(\"\\nComplete counting naive word frequency of negative set\")\n",
    "    \n",
    "    totalString = str()\n",
    "    count = 0\n",
    "    lenW = len(dataSet['all'])\n",
    "    \n",
    "    print(\"Start counting naive word frequency of all set\")\n",
    "    \n",
    "    for comment in dataSet['all']:\n",
    "        totalString = totalString + ' ' + comment['comment'].lower()\n",
    "        \n",
    "        # This is for loading bar\n",
    "        sys.stdout.write('\\r')\n",
    "        c = int((float(count) / float(lenW)) * 100)\n",
    "        sys.stdout.write(\"[%-20s] %d%%\" % ('='*int(c / 5), c))\n",
    "        sleep(0.001)\n",
    "        sys.stdout.flush()\n",
    "        count += 1\n",
    "    \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    withoutPunc = tokenizer.tokenize(totalString)\n",
    "    stopwordsSet = set(stopwords.words())\n",
    "    allCountDict = Counter(s.lower() for s in withoutPunc if s.lower() not in stopwordsSet)\n",
    "    print(\"\\nComplete counting naive word frequency of all set\")\n",
    "    \n",
    "    stopwordCount = {'pos':posCountDict, 'neg':negCountDict, 'all':allCountDict}\n",
    "    \n",
    "    return stopwordCount\n",
    "\n",
    "# stopwordFrequency = wordsFrequencyStopword(trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(stopwordFrequency.most_common(160))\\nprint(\"Size of stopwordFrequency: \", len(stopwordFrequency))\\nprint(\"Example: br = \", stopwordFrequency[\\'br\\'])\\nprint(stopwordFrequency_neg.most_common(160))\\nprint(\"Size of stopwordFrequency_neg: \", len(stopwordFrequency_neg))\\nprint(\"Example: movie = \", stopwordFrequency_neg[\\'movie\\'])\\nprint(stopwordFrequency_pos.most_common(160))\\nprint(\"Size of stopwordFrequency_pos: \", len(stopwordFrequency_pos))\\nprint(\"Example: movie = \", stopwordFrequency_pos[\\'film\\'])\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of word frequency without stopwords\n",
    "'''\n",
    "print(stopwordFrequency.most_common(160))\n",
    "print(\"Size of stopwordFrequency: \", len(stopwordFrequency))\n",
    "print(\"Example: br = \", stopwordFrequency['br'])\n",
    "print(stopwordFrequency_neg.most_common(160))\n",
    "print(\"Size of stopwordFrequency_neg: \", len(stopwordFrequency_neg))\n",
    "print(\"Example: movie = \", stopwordFrequency_neg['movie'])\n",
    "print(stopwordFrequency_pos.most_common(160))\n",
    "print(\"Size of stopwordFrequency_pos: \", len(stopwordFrequency_pos))\n",
    "print(\"Example: movie = \", stopwordFrequency_pos['film'])\n",
    "'''\n",
    "# print(stopwordFrequency['all'].most_common(160))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 0.4 - Number of Naive Existance of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @author Pengnan Fan\n",
    "# @param dataSet: set of comments\n",
    "# @return naiveCount: list of words of num of naive existances\n",
    "def numOfExistanceNaive(dataSet):\n",
    "    naiveCount = dict()\n",
    "    totalComments = []\n",
    "    count = 0\n",
    "    lenW = len(dataSet['pos'])\n",
    "    \n",
    "    print(\"Start counting number of naive word existance of positive set\")\n",
    "    for comment in dataSet['pos']:\n",
    "        commentSplit = comment['comment'].lower().split(\" \")\n",
    "        wordsToAdd = []\n",
    "        for word in commentSplit:\n",
    "            if word not in wordsToAdd:\n",
    "                wordsToAdd.append(word)\n",
    "        totalComments+=wordsToAdd\n",
    "        \n",
    "        # This is for loading bar\n",
    "        sys.stdout.write('\\r')\n",
    "        c = int((float(count) / float(lenW)) * 100)\n",
    "        sys.stdout.write(\"[%-20s] %d%%\" % ('='*int(c / 5), c))\n",
    "        sleep(0.001)\n",
    "        sys.stdout.flush()\n",
    "        count += 1\n",
    "    \n",
    "    posCount = Counter(x for x in totalComments)\n",
    "    print(\"\\nComplete counting number of naive word existance of positive set\")\n",
    "    \n",
    "    totalComments = []\n",
    "    count = 0\n",
    "    lenW = len(dataSet['neg'])\n",
    "    \n",
    "    print(\"Start counting number of naive word existance of negative set\")\n",
    "    for comment in dataSet['neg']:\n",
    "        commentSplit = comment['comment'].lower().split(\" \")\n",
    "        wordsToAdd = []\n",
    "        for word in commentSplit:\n",
    "            if word not in wordsToAdd:\n",
    "                wordsToAdd.append(word)\n",
    "        totalComments+=wordsToAdd\n",
    "        \n",
    "        # This is for loading bar\n",
    "        sys.stdout.write('\\r')\n",
    "        c = int((float(count) / float(lenW)) * 100)\n",
    "        sys.stdout.write(\"[%-20s] %d%%\" % ('='*int(c / 5), c))\n",
    "        sleep(0.001)\n",
    "        sys.stdout.flush()\n",
    "        count += 1\n",
    "        \n",
    "    negCount = Counter(x for x in totalComments)\n",
    "    print(\"\\nComplete counting number of naive word existance of negative set\")\n",
    "    \n",
    "    totalComments = []\n",
    "    count = 0\n",
    "    lenW = len(dataSet['all'])\n",
    "    \n",
    "    print(\"Start counting number of naive word existance of all set\")\n",
    "    for comment in dataSet['all']:\n",
    "        commentSplit = comment['comment'].lower().split(\" \")\n",
    "        wordsToAdd = []\n",
    "        for word in commentSplit:\n",
    "            if word not in wordsToAdd:\n",
    "                wordsToAdd.append(word)\n",
    "        totalComments+=wordsToAdd\n",
    "        \n",
    "        # This is for loading bar\n",
    "        sys.stdout.write('\\r')\n",
    "        c = int((float(count) / float(lenW)) * 100)\n",
    "        sys.stdout.write(\"[%-20s] %d%%\" % ('='*int(c / 5), c))\n",
    "        sleep(0.001)\n",
    "        sys.stdout.flush()\n",
    "        count += 1\n",
    "        \n",
    "    allCount = Counter(x for x in totalComments)\n",
    "    print(\"\\nComplete counting number of naive word existance of all set\")\n",
    "    \n",
    "    naiveCount = {'pos':posCount, 'neg':negCount, 'all':allCount}\n",
    "    \n",
    "    return naiveCount\n",
    "\n",
    "# naiveNumOfExistance = numOfExistanceNaive(trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(naiveNumOfExistance.most_common(160))\\nprint(\"Size of naiveNumOfExistance: \", len(naiveNumOfExistance))\\nprint(\"Example: the = \", naiveNumOfExistance[\\'the\\'])\\nprint(naiveNumOfExistance_neg.most_common(160))\\nprint(\"Size of naiveNumOfExistance_neg: \", len(naiveNumOfExistance_neg))\\nprint(\"Example: the = \", naiveNumOfExistance_neg[\\'the\\'])\\nprint(naiveNumOfExistance_pos.most_common(160))\\nprint(\"Size of naiveNumOfExistance_pos: \", len(naiveNumOfExistance_pos))\\nprint(\"Example: the = \", naiveNumOfExistance_pos[\\'the\\'])\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of number of naive existance of words\n",
    "'''\n",
    "print(naiveNumOfExistance.most_common(160))\n",
    "print(\"Size of naiveNumOfExistance: \", len(naiveNumOfExistance))\n",
    "print(\"Example: the = \", naiveNumOfExistance['the'])\n",
    "print(naiveNumOfExistance_neg.most_common(160))\n",
    "print(\"Size of naiveNumOfExistance_neg: \", len(naiveNumOfExistance_neg))\n",
    "print(\"Example: the = \", naiveNumOfExistance_neg['the'])\n",
    "print(naiveNumOfExistance_pos.most_common(160))\n",
    "print(\"Size of naiveNumOfExistance_pos: \", len(naiveNumOfExistance_pos))\n",
    "print(\"Example: the = \", naiveNumOfExistance_pos['the'])\n",
    "'''\n",
    "# print(naiveNumOfExistance['pos'].most_common(160))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 0.5 - Number of Existance of Words without Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start counting number of words without stopwords of existance of positive set\n",
      "[=================== ] 99%\n",
      "Complete counting number of words without stopwords of existance of positive set\n",
      "Start counting number of words without stopwords of existance of negative set\n",
      "[=================== ] 99%\n",
      "Complete counting number of words without stopwords of existance of negative set\n",
      "Start counting number of words without stopwords of existance of all set\n",
      "[=================== ] 99%\n",
      "Complete counting number of words without stopwords of existance of all set\n"
     ]
    }
   ],
   "source": [
    "# @author Pengnan Fan\n",
    "# @param dataSet: set of comments\n",
    "# @return naiveCount: list of num of existances of words without stopwords\n",
    "def advancedNumOfExistance(dataSet):\n",
    "    countDict = dict()\n",
    "    stopwordsSet = set(stopwords.words())\n",
    "    stopwordsSet.add('br')\n",
    "    \n",
    "    wordSet = list()\n",
    "    count = 0\n",
    "    lenW = len(dataSet['pos'])\n",
    "    \n",
    "    print(\"Start counting number of words without stopwords of existance of positive set\")\n",
    "    for exp in dataSet['pos']: \n",
    "        comment = contractions.fix(exp['comment'].lower())\n",
    "        sent_map = comment.maketrans(dict.fromkeys(string.punctuation))\n",
    "        sent_clean = comment.translate(sent_map)\n",
    "        processedComment = ([k for k, v in groupby(sent_clean.split())])\n",
    "        wordSet+=processedComment\n",
    "        \n",
    "        # This is for loading bar\n",
    "        sys.stdout.write('\\r')\n",
    "        c = int((float(count) / float(lenW)) * 100)\n",
    "        sys.stdout.write(\"[%-20s] %d%%\" % ('='*int(c / 5), c))\n",
    "        sleep(0.001)\n",
    "        sys.stdout.flush()\n",
    "        count += 1\n",
    "        \n",
    "    posDict = Counter(s for s in wordSet if s not in stopwordsSet)\n",
    "    \n",
    "    print(\"\\nComplete counting number of words without stopwords of existance of positive set\")\n",
    "    \n",
    "    wordSet = list()\n",
    "    count = 0\n",
    "    lenW = len(dataSet['neg'])\n",
    "    \n",
    "    print(\"Start counting number of words without stopwords of existance of negative set\")\n",
    "    for exp in dataSet['neg']: \n",
    "        comment = contractions.fix(exp['comment'].lower())\n",
    "        sent_map = comment.maketrans(dict.fromkeys(string.punctuation))\n",
    "        sent_clean = comment.translate(sent_map)\n",
    "        processedComment = ([k for k, v in groupby(sent_clean.split())])\n",
    "        wordSet+=processedComment\n",
    "            \n",
    "        # This is for loading bar\n",
    "        sys.stdout.write('\\r')\n",
    "        c = int((float(count) / float(lenW)) * 100)\n",
    "        sys.stdout.write(\"[%-20s] %d%%\" % ('='*int(c / 5), c))\n",
    "        sleep(0.001)\n",
    "        sys.stdout.flush()\n",
    "        count += 1\n",
    "    \n",
    "    negDict = Counter(s for s in wordSet if s not in stopwordsSet)\n",
    "    \n",
    "    print(\"\\nComplete counting number of words without stopwords of existance of negative set\")\n",
    "    \n",
    "    wordSet = list()\n",
    "    count = 0\n",
    "    lenW = len(dataSet['all'])\n",
    "    \n",
    "    print(\"Start counting number of words without stopwords of existance of all set\")\n",
    "    for exp in dataSet['all']: \n",
    "        comment = contractions.fix(exp['comment'].lower())\n",
    "        sent_map = comment.maketrans(dict.fromkeys(string.punctuation))\n",
    "        sent_clean = comment.translate(sent_map)\n",
    "        processedComment = ([k for k, v in groupby(sent_clean.split())])\n",
    "        wordSet+=processedComment\n",
    "            \n",
    "        # This is for loading bar\n",
    "        sys.stdout.write('\\r')\n",
    "        c = int((float(count) / float(lenW)) * 100)\n",
    "        sys.stdout.write(\"[%-20s] %d%%\" % ('='*int(c / 5), c))\n",
    "        sleep(0.001)\n",
    "        sys.stdout.flush()\n",
    "        count += 1     \n",
    "    \n",
    "    allDict = Counter(s for s in wordSet if s not in stopwordsSet)\n",
    "    \n",
    "    print(\"\\nComplete counting number of words without stopwords of existance of all set\")\n",
    "    \n",
    "    countDict = {'neg':negDict, 'pos':posDict, 'all':allDict}\n",
    "    \n",
    "    return countDict\n",
    "\n",
    "\n",
    "advancedNumOfExistance = advancedNumOfExistance(trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('movie', 23666), ('film', 17863), ('one', 12430), ('like', 10909), ('would', 9077), ('even', 7605), ('good', 7157), ('bad', 7003), ('really', 6074), ('time', 5779), ('could', 5703), ('see', 5378), ('get', 4981), ('story', 4969), ('much', 4928), ('people', 4636), ('make', 4548), ('made', 4342), ('first', 4237), ('movies', 4131), ('plot', 3964), ('acting', 3932), ('way', 3785), ('well', 3731), ('characters', 3687), ('think', 3612), ('films', 3462), ('watch', 3460), ('know', 3267), ('character', 3249), ('better', 3232), ('never', 3223), ('seen', 3180), ('ever', 3152), ('little', 3068), ('two', 3042), ('say', 2947), ('nothing', 2926), ('many', 2841), ('something', 2825), ('cannot', 2816), ('thing', 2783), ('show', 2761), ('scenes', 2708), ('scene', 2705), ('go', 2616), ('great', 2597), ('watching', 2591), ('going', 2438), ('worst', 2436), ('actually', 2431), ('actors', 2391), ('back', 2314), ('still', 2255), ('another', 2226), ('look', 2198), ('funny', 2196), ('us', 2192), ('life', 2177), ('pretty', 2099), ('real', 2070), ('love', 2065), ('director', 2058), ('minutes', 2049), ('best', 2041), ('seems', 2019), ('got', 2018), ('every', 2014), ('though', 2010), ('least', 1984), ('script', 1983), ('horror', 1976), ('old', 1963), ('enough', 1953), ('original', 1935), ('around', 1898), ('work', 1882), ('part', 1882), ('lot', 1865), ('find', 1854), ('guy', 1847), ('anything', 1830), ('give', 1821), ('fact', 1818), ('new', 1806), ('things', 1804), ('makes', 1803), ('ive', 1802), ('take', 1778), ('point', 1761), ('whole', 1758), ('thought', 1749), ('years', 1749), ('gets', 1719), ('however', 1710), ('might', 1652), ('cast', 1622), ('interesting', 1603), ('long', 1596), ('big', 1587), ('without', 1583), ('quite', 1583), ('money', 1568), ('almost', 1558), ('right', 1537), ('far', 1529), ('let', 1528), ('looks', 1517), ('kind', 1516), ('must', 1499), ('making', 1486), ('reason', 1485), ('trying', 1480), ('2', 1473), ('saw', 1463), ('done', 1444), ('probably', 1436), ('instead', 1434), ('poor', 1432), ('action', 1426), ('believe', 1420), ('awful', 1419), ('away', 1413), ('someone', 1412), ('sure', 1409), ('comedy', 1396), ('rather', 1391), ('boring', 1389), ('may', 1380), ('last', 1378), ('since', 1364), ('maybe', 1360), ('anyone', 1356), ('waste', 1351), ('times', 1341), ('stupid', 1336), ('feel', 1332), ('terrible', 1327), ('girl', 1318), ('effects', 1289), ('young', 1285), ('idea', 1276), ('bit', 1275), ('looking', 1272), ('music', 1262), ('tv', 1257), ('found', 1256), ('world', 1252), ('put', 1247), ('sense', 1246), ('woman', 1245), ('goes', 1240), ('hard', 1239), ('comes', 1219), ('main', 1217), ('book', 1207), ('said', 1206), ('supposed', 1185), ('worse', 1184), ('series', 1170)]\n",
      "[('movie', 41805), ('film', 37453), ('one', 25494), ('like', 19638), ('would', 15825), ('good', 14549), ('even', 12502), ('time', 11776), ('really', 11473), ('story', 11454), ('see', 11222), ('much', 9508), ('could', 9381), ('well', 9254), ('get', 9211), ('people', 8945), ('great', 8882), ('first', 8857), ('bad', 8831), ('made', 7990), ('movies', 7787), ('make', 7733), ('films', 7725), ('way', 7653), ('characters', 7290), ('think', 7229), ('watch', 6776), ('two', 6643), ('many', 6551), ('seen', 6530), ('character', 6514), ('never', 6419), ('little', 6387), ('acting', 6289), ('plot', 6273), ('best', 6263), ('love', 6210), ('show', 6083), ('know', 6038), ('life', 5987), ('ever', 5778), ('still', 5561), ('better', 5546), ('say', 5330), ('scene', 5169), ('scenes', 5059), ('go', 4983), ('something', 4888), ('cannot', 4811), ('back', 4759), ('us', 4704), ('watching', 4511), ('real', 4493), ('years', 4455), ('though', 4415), ('thing', 4388), ('actors', 4376), ('another', 4264), ('going', 4262), ('new', 4233), ('actually', 4211), ('nothing', 4199), ('makes', 4186), ('find', 4109), ('work', 4089), ('funny', 4059), ('look', 4052), ('old', 4028), ('every', 3960), ('lot', 3925), ('part', 3904), ('director', 3805), ('quite', 3713), ('got', 3702), ('cast', 3687), ('pretty', 3638), ('things', 3635), ('seems', 3604), ('young', 3593), ('around', 3530), ('fact', 3482), ('however', 3471), ('world', 3455), ('take', 3451), ('enough', 3377), ('give', 3371), ('may', 3349), ('ive', 3336), ('big', 3327), ('horror', 3311), ('original', 3297), ('thought', 3295), ('without', 3241), ('gets', 3212), ('always', 3204), ('series', 3198), ('right', 3170), ('saw', 3141), ('long', 3136), ('must', 3103), ('almost', 3101), ('times', 3089), ('least', 3072), ('point', 3067), ('role', 3067), ('action', 3056), ('interesting', 3052), ('whole', 3047), ('comedy', 3007), ('bit', 3003), ('family', 2988), ('done', 2929), ('music', 2926), ('might', 2911), ('script', 2907), ('last', 2899), ('anything', 2886), ('guy', 2859), ('since', 2859), ('feel', 2857), ('minutes', 2848), ('probably', 2825), ('performance', 2813), ('far', 2802), ('kind', 2733), ('rather', 2726), ('worst', 2682), ('yet', 2669), ('away', 2658), ('sure', 2633), ('let', 2618), ('tv', 2586), ('making', 2583), ('woman', 2578), ('girl', 2566), ('found', 2554), ('fun', 2542), ('played', 2536), ('anyone', 2531), ('although', 2490), ('believe', 2479), ('comes', 2476), ('trying', 2462), ('course', 2456), ('especially', 2432), ('goes', 2412), ('day', 2403), ('looks', 2397), ('hard', 2392), ('put', 2341), ('different', 2338), ('place', 2293), ('maybe', 2279), ('shows', 2275), ('book', 2271), ('set', 2261), ('main', 2255), ('reason', 2253), ('money', 2253), ('worth', 2248)]\n"
     ]
    }
   ],
   "source": [
    "# An example of number of existance of words without stopwords\n",
    "'''\n",
    "print(stopwordNumOfExistance.most_common(160))\n",
    "print(\"Size of stopwordNumOfExistance: \", len(stopwordNumOfExistance))\n",
    "print(\"Example: br = \", stopwordNumOfExistance['br'])\n",
    "print(naiveNumOfExistance_neg.most_common(160))\n",
    "print(\"Size of stopwordNumOfExistance_neg: \", len(stopwordNumOfExistance_neg))\n",
    "print(\"Example: movie = \", stopwordNumOfExistance_neg['movie'])\n",
    "print(naiveNumOfExistance_pos.most_common(160))\n",
    "print(\"Size of stopwordNumOfExistance_pos: \", len(stopwordNumOfExistance_pos))\n",
    "print(\"Example: movie = \", stopwordNumOfExistance_pos['film'])\n",
    "'''\n",
    "print(advancedNumOfExistance['neg'].most_common(160)) \n",
    "print(advancedNumOfExistance['all'].most_common(160))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 0.6 - Data Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start proceeding data\n",
      "[=================== ] 99%\n",
      "Complete proceeding data\n"
     ]
    }
   ],
   "source": [
    "# @author Pengnan Fan\n",
    "# @param dataSet\n",
    "# @return proceedData\n",
    "def dataStandardization(dataSet):\n",
    "    proceedData = list()\n",
    "    stopwordsSet = set(stopwords.words())\n",
    "    stopwordsSet.add('br')\n",
    "    \n",
    "    count = 0\n",
    "    lenW = len(dataSet)\n",
    "    \n",
    "    print(\"Start proceeding data\")\n",
    "    for data in dataSet: \n",
    "        comment = contractions.fix(data['comment'].lower())\n",
    "        sent_map = comment.maketrans(dict.fromkeys(string.punctuation))\n",
    "        sent_clean = comment.translate(sent_map)\n",
    "        processedComment = sent_clean.split()\n",
    "        toAdd = list()\n",
    "        for x in processedComment:\n",
    "            if x not in stopwordsSet and x not in toAdd:\n",
    "                toAdd.append(x)\n",
    "                \n",
    "        proceedData.append(toAdd)\n",
    "        \n",
    "        # This is for loading bar\n",
    "        sys.stdout.write('\\r')\n",
    "        c = int((float(count) / float(lenW)) * 100)\n",
    "        sys.stdout.write(\"[%-20s] %d%%\" % ('='*int(c / 5), c))\n",
    "        sleep(0.001)\n",
    "        sys.stdout.flush()\n",
    "        count += 1\n",
    "        \n",
    "    print(\"\\nComplete proceeding data\")\n",
    "    return proceedData\n",
    "\n",
    "proceedData_All = dataStandardization(trainSet['all'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1 - Bernoulli Naive Bayes (Bugs here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Bernoulli naive Bayes classifying\n",
      "[=================== ] 99%\n",
      "Complete Bernoulli naive Bayes classifying\n"
     ]
    }
   ],
   "source": [
    "# @author Pengnan Fan\n",
    "# @param dataSet: set for prediction\n",
    "# @param wordExistance: dict {'pos' -> pos word existance, 'neg' -> neg word existance, 'all' -> all word existance}\n",
    "# @param size: dict {'pos' -> pos size, 'neg' -> neg size, 'all' -> all size}\n",
    "# @return prediction\n",
    "def bernoulliNaiveBayes(dataSet, wordExistance, size):\n",
    "    pPos = size['pos']/size['all']\n",
    "    pNeg = size['neg']/size['all']\n",
    "    prediction = list()\n",
    "    count = 0\n",
    "    lenW = len(dataSet)\n",
    "    print(\"Start Bernoulli naive Bayes classifying\")\n",
    "    for exp in dataSet:\n",
    "        pPos_x = pPos\n",
    "        pNeg_x = pNeg\n",
    "        \n",
    "        for word in exp:\n",
    "            pPos_x *= (wordExistance['pos'][word]+1)/(wordExistance['all'][word]+2)\n",
    "            pNeg_x *= (wordExistance['neg'][word]+1)/(wordExistance['all'][word]+2)\n",
    "        \n",
    "        log_ratio = numpy.log([pPos_x/pNeg_x])\n",
    "        \n",
    "        if log_ratio > 0:\n",
    "            prediction.append(1)\n",
    "        else:\n",
    "            prediction.append(0)\n",
    "        \n",
    "        # This is for loading bar\n",
    "        sys.stdout.write('\\r')\n",
    "        c = int((float(count) / float(lenW)) * 100)\n",
    "        sys.stdout.write(\"[%-20s] %d%%\" % ('='*int(c / 5), c))\n",
    "        sleep(0.001)\n",
    "        sys.stdout.flush()\n",
    "        count += 1\n",
    "    \n",
    "    print(\"\\nComplete Bernoulli naive Bayes classifying\")\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "size = dict()\n",
    "size = {'pos':len(trainSet['pos']), 'neg':len(trainSet['neg']), 'all':len(trainSet['all'])}\n",
    "pred = bernoulliNaiveBayes(proceedData_All, advancedNumOfExistance, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2 - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start evaluating classification\n",
      "[=================== ] 99%\n",
      "Complete evaluating classification\n",
      "TP =  11848 \n",
      "TN =  11482 \n",
      "FP =  1018 \n",
      "FN =  652\n"
     ]
    }
   ],
   "source": [
    "# @author Pengnan Fan\n",
    "# @param dataSet: train set with label\n",
    "# @param prediction: prediction of each example in the trainSet\n",
    "# @return result: list of results: {TP: true pos, TN: true neg, FP: false pos, FN: false neg}\n",
    "def evaluation(dataSet, prediction):\n",
    "    size = len(prediction)\n",
    "    count = 0\n",
    "    result = {'TP':0,'TN':0,'FP':0,'FN':0}\n",
    "    \n",
    "    print(\"Start evaluating classification\")\n",
    "    for i in range(size):\n",
    "        if prediction[i]==1:\n",
    "            if dataSet[i]['isPos']==1:\n",
    "                result['TP']+=1\n",
    "            else:\n",
    "                result['FP']+=1\n",
    "        else:\n",
    "            if dataSet[i]['isPos']==1:\n",
    "                result['FN']+=1\n",
    "            else:\n",
    "                result['TN']+=1\n",
    "                \n",
    "        # This is for loading bar\n",
    "        sys.stdout.write('\\r')\n",
    "        c = int((float(count) / float(size)) * 100)\n",
    "        sys.stdout.write(\"[%-20s] %d%%\" % ('='*int(c / 5), c))\n",
    "        sleep(0.001)\n",
    "        sys.stdout.flush()\n",
    "        count += 1\n",
    "    print(\"\\nComplete evaluating classification\")\n",
    "    return result\n",
    "\n",
    "eva = evaluation(trainSet['all'], pred)\n",
    "print(\"TP = \", eva['TP'], \"\\nTN = \", eva['TN'], \"\\nFP = \", eva['FP'], \"\\nFN = \", eva['FN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  93.32 %\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy = \", (eva['TP']+eva['TN'])/250, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
