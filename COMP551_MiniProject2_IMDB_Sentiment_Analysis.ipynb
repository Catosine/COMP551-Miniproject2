{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP551 Mini Project 2 - IMDB Sentiment Analysis  \n",
    "This is the codes of mini project2 - IMDB Sentiment Analysis.  \n",
    "\n",
    "## AUTHORS\n",
    "Pengnan Fan, ID#260768510  \n",
    "\n",
    "## TASKS\n",
    "1. **Bernoulli Naive Bayes** (w/o any external library).  \n",
    "2. **At least 2** out of 3 classifiers from the SciKit. i.e. suggestions: logistic regression, decision tree, or support vector machines  \n",
    "3. **At least 2** different features extraction pipelines for processing the data.  \n",
    "4. A model validation. i.e. **K-fold cross validation**  \n",
    "\n",
    "## UPDATES\n",
    "**<January 6, 2019>** Pengnan Fan create this notebook and implements functions readTrainData and readTestData  \n",
    "> * **readTrainData(address:String):DataFrame**  \n",
    "> This function takes a string **address** which indicates the address of your train data and will load comments and isPositive to a DataFrame.\n",
    "> * **readTestData(address:String):DataFrame**  \n",
    "> This function takes a string **address** which indicates the address of your test data and will load comments and isPositive to a DataFrame. **Note: all isPositive is initialized as 0**  \n",
    "> * **Learning set** 25000 in total\n",
    "> * **Test set** 25000 in total  \n",
    "\n",
    "**<January 7, 2019>** Pengnan Fan implements wordsFrequencyNaive and wordsFrequencyStopword\n",
    "> * **wordsFrequencyNaive(dataSet:DataFrame)**  \n",
    "> This function takes a DataFrame **dataSet** and calculate the naive word frequency  \n",
    "> * **wordsFrequencyStopword(dataSet:DataFrame)**  \n",
    "> This function takes a DataFrame **dataSet** and calculate the word frequency without stopwords  \n",
    "\n",
    "**<January 9, 2019>** Pengnan Fan uses sklearn.datasets.load_files(address:str) to load all datas. It helps to increase the speed of loading. And the implementation of Bernoulli naive Bayes has been started.  \n",
    "> * **sklearn.datasets.load_files** - [Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_files.html)\n",
    "\n",
    "**<January 10, 2019>** Pengnan Fan implements numOfExistanceNaive and numOfExistanceStopword\n",
    "> * **numOfExistanceNaive(dataset:Bunch)**  \n",
    "> This function takes a Bunch **dataSet** and calculate the naive existance of words  \n",
    "> * **numOfExistanceStopword(dataset:Bunch)**  \n",
    "> This funciton takes a Bunch **dataSet** and calculate the existance of words without stopwords  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import sys\n",
    "from time import sleep\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "import numpy\n",
    "import scipy\n",
    "import sklearn.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0 - Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 0.1 - Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading train set\n",
      "Complete loading train set\n",
      "Start loading train set - negative\n",
      "Complete loading train set - negative\n",
      "Start loading train set - postive\n",
      "Complete loading train set - postive\n",
      "Start loading test set\n",
      "Complete loading test set\n"
     ]
    }
   ],
   "source": [
    "# Task 0 - Preprocessing Data\n",
    "\n",
    "# Please add your address here as string\n",
    "ADDRESS_TRAIN_PENGNAN = \"D:\\\\McGill\\\\19Fall\\\\COMP 551\\\\Projects\\\\Project2\\\\comp-551-imbd-sentiment-classification\\\\train\"\n",
    "ADDRESS_TEST_PENGNAN = \"D:\\\\McGill\\\\19Fall\\\\COMP 551\\\\Projects\\\\Project2\\\\comp-551-imbd-sentiment-classification\\\\test\"\n",
    "\n",
    "'''\n",
    "# @author Pengnan Fan\n",
    "# @param address: address of your train data file as string\n",
    "# @return output: DataFrame{'comment':comments, 'isPositive':[0,1]}\n",
    "def readTrainData(address):\n",
    "    \n",
    "    print(\"Start reading learning set\")\n",
    "    # Read negative data as DataFrame\n",
    "    comment = []\n",
    "    isPositive = []\n",
    "    allNegFiles = glob.glob(address+\"\\\\neg\" + \"/*.txt\")\n",
    "    count = 0\n",
    "    lenN = len(allNegFiles)\n",
    "    for file in allNegFiles:\n",
    "        comment.append(pd.read_csv(file, quotechar=None, quoting=3, delimiter='\\r').columns[0])\n",
    "        isPositive.append(0)\n",
    "        \n",
    "        # This is for loading bar\n",
    "        sys.stdout.write('\\r')\n",
    "        c = int((float(count) / float(lenN)) * 100)\n",
    "        sys.stdout.write(\"Start reading negative comments: [%-20s] %d%%\" % ('='*int(c / 5), c))\n",
    "        sleep(0.001)\n",
    "        sys.stdout.flush()\n",
    "        count += 1\n",
    "        \n",
    "    print(\"\\nComplete reading negative comments\")\n",
    "    \n",
    "    # Read positive data as DataFrame\n",
    "    allPosFiles = glob.glob(address+\"\\\\pos\" + \"/*.txt\")\n",
    "    count = 0\n",
    "    lenP = len(allPosFiles)\n",
    "    for file in allPosFiles:\n",
    "        comment.append(pd.read_csv(file, quotechar=None, quoting=3, delimiter='\\r').columns[0])\n",
    "        isPositive.append(1)\n",
    "        \n",
    "        # This is for loading bar\n",
    "        c = int((float(count) / float(lenP)) * 100)\n",
    "        sys.stdout.write('\\r')\n",
    "        sys.stdout.write(\"Start reading positive comments: [%-20s] %d%%\" % ('='*int(c / 5), c))\n",
    "        sleep(0.001)\n",
    "        sys.stdout.flush()\n",
    "        count += 1\n",
    "        \n",
    "    print(\"\\nComplete reading postive comments\")\n",
    "    print(\"Complete reading learning set\\n\")\n",
    "    \n",
    "    output = pd.DataFrame({'comment':comment, 'isPositive':isPositive})\n",
    "    return output\n",
    "\n",
    "# @author Pengnan Fan\n",
    "# @param address: address of your test data file as string\n",
    "# @return output: DataFrame{'comment':comments, 'isPositive':[0,1]}\n",
    "# Note: all isPositive is initialized as 0\n",
    "def readTestData(address):\n",
    "    \n",
    "    # Read negative data as DataFrame\n",
    "    comment = []\n",
    "    isPositive = []\n",
    "    allFiles = glob.glob(address+\"/*.txt\")\n",
    "    count = 0\n",
    "    lenN = len(allFiles)\n",
    "    for file in allFiles:\n",
    "        comment.append(pd.read_csv(file, quotechar=None, quoting=3, delimiter='\\r').columns[0])\n",
    "        isPositive.append(0)\n",
    "        \n",
    "        # This is for loading bar\n",
    "        sys.stdout.write('\\r')\n",
    "        c = int((float(count) / float(lenN)) * 100)\n",
    "        sys.stdout.write(\"Start reading test set: [%-20s] %d%%\" % ('='*int(c / 5), c))\n",
    "        sleep(0.001)\n",
    "        sys.stdout.flush()\n",
    "        count += 1\n",
    "        \n",
    "    print(\"\\nComplete reading test set\")\n",
    "    \n",
    "    output = pd.DataFrame({'comment':comment, 'isPositive':isPositive})\n",
    "    return output\n",
    "\n",
    "learningSet = readTrainData(ADDRESS_TRAIN_PENGNAN)\n",
    "testSet = readTestData(ADDRESS_TEST_PENGNAN)\n",
    "'''\n",
    "\n",
    "# Advanced loader\n",
    "# @return: Bunch\n",
    "print(\"Start loading train set\")\n",
    "trainSet = sklearn.datasets.load_files(ADDRESS_TRAIN_PENGNAN)\n",
    "print(\"Complete loading train set\")\n",
    "\n",
    "print(\"Start loading train set - negative\")\n",
    "trainSet_neg = sklearn.datasets.load_files(ADDRESS_TRAIN_PENGNAN, categories={\"neg\"})\n",
    "print(\"Complete loading train set - negative\")\n",
    "\n",
    "print(\"Start loading train set - postive\")\n",
    "trainSet_pos = sklearn.datasets.load_files(ADDRESS_TRAIN_PENGNAN, categories={\"pos\"})\n",
    "print(\"Complete loading train set - postive\")\n",
    "\n",
    "print(\"Start loading test set\")\n",
    "testSet = sklearn.datasets.load_files(ADDRESS_TEST_PENGNAN)\n",
    "print(\"Complete loading test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data set has a structure of:\n",
      "data :  <class 'str'>\n",
      "filenames :  <class 'str'>\n",
      "target_names :  <class 'str'>\n",
      "target :  <class 'str'>\n",
      "DESCR :  <class 'str'>\n",
      "Here are some examples:\n",
      "data:  Zero Day leads you to think, even re-think why two boys/young men would do what they did - commit mutual suicide via slaughtering their classmates. It captures what must be beyond a bizarre mode of being for two humans who have decided to withdraw from common civility in order to define their own/mutual world via coupled destruction.<br /><br />It is not a perfect movie but given what money/time the filmmaker and actors had - it is a remarkable product. In terms of explaining the motives and actions of the two young suicide/murderers it is better than 'Elephant' - in terms of being a film that gets under our 'rationalistic' skin it is a far, far better film than almost anything you are likely to see. <br /><br />Flawed but honest with a terrible honesty.\n",
      "target_names:  neg\n",
      "The rest are irrelevent to this project.\n",
      "NOTE: Type \"data\" is in Byte mode. You need to transform them into string by using .decode(\"utf-8\")\n"
     ]
    }
   ],
   "source": [
    "# An example of the dataset\n",
    "'''\n",
    "print(\"The first learning set comment is:\\n\", learningSet['comment'][0],'\\nisPositive: ', learningSet['isPositive'][0])\n",
    "print(\"The total size of learning set: \", len(learningSet.comment))\n",
    "print(\"The first test comment is:\\n\", testSet['comment'][0])\n",
    "print(\"The total size of test set: \", len(testSet.comment))\n",
    "'''\n",
    "print(\"The data set has a structure of:\")\n",
    "for dataPoint in trainSet:\n",
    "    print(dataPoint,\": \", type(dataPoint))\n",
    "print(\"Here are some examples:\")\n",
    "print(\"data: \", trainSet.data[0].decode(\"utf-8\"))\n",
    "print(\"target_names: \", trainSet.target_names[0])\n",
    "print(\"The rest are irrelevent to this project.\\nNOTE: Type \\\"data\\\" is in Byte mode. You need to transform them into string by using .decode(\\\"utf-8\\\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 0.2 - Naive Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start counting naive word frequency: [=================== ] 99%\n",
      "Complete counting naive word frequency\n",
      "Start counting naive word frequency: [=================== ] 99%\n",
      "Complete counting naive word frequency\n",
      "Start counting naive word frequency: [=================== ] 99%\n",
      "Complete counting naive word frequency\n"
     ]
    }
   ],
   "source": [
    "# @author Pengnan Fan\n",
    "# @param dataSet: set of comments\n",
    "# @return naiveCount: naive word frequency\n",
    "def wordsFrequencyNaive(dataSet):\n",
    "    totalComments = []\n",
    "    count = 0\n",
    "    lenW = len(dataSet.data)\n",
    "    for comment in dataSet.data:\n",
    "        totalComments+=comment.decode(\"utf-8\").lower().split(\" \")\n",
    "        \n",
    "        # This is for loading bar\n",
    "        sys.stdout.write('\\r')\n",
    "        c = int((float(count) / float(lenW)) * 100)\n",
    "        sys.stdout.write(\"Start counting naive word frequency: [%-20s] %d%%\" % ('='*int(c / 5), c))\n",
    "        sleep(0.001)\n",
    "        sys.stdout.flush()\n",
    "        count += 1\n",
    "    \n",
    "    print(\"\\nComplete counting naive word frequency\")\n",
    "    \n",
    "    naiveCount = Counter(x for x in totalComments)\n",
    "    return naiveCount\n",
    "\n",
    "naiveFrequency = wordsFrequencyNaive(trainSet)\n",
    "naiveFrequency_neg = wordsFrequencyNaive(trainSet_neg)\n",
    "naiveFrequency_pos = wordsFrequencyNaive(trainSet_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 322174), ('a', 159949), ('and', 158556), ('of', 144459), ('to', 133965), ('is', 104170), ('in', 90521), ('i', 70477), ('this', 69711), ('that', 66287), ('it', 65489), ('/><br', 50935), ('was', 47023), ('as', 45098), ('for', 42839), ('with', 42725), ('but', 39757), ('on', 31618), ('movie', 30883), ('his', 29058), ('are', 28742), ('not', 28591), ('film', 27774), ('you', 27558), ('have', 27343), ('he', 26175), ('be', 25690), ('at', 22730), ('one', 22477), ('by', 21974), ('an', 21239), ('they', 20623), ('from', 19933), ('all', 19738), ('who', 19407), ('like', 18779), ('so', 18095), ('just', 17308), ('or', 16765), ('has', 16570), ('her', 16538), ('about', 16486), (\"it's\", 15969), ('some', 15280), ('if', 15184), ('out', 14509), ('what', 14053), ('very', 13633), ('when', 13608), ('more', 13168), ('there', 13093), ('she', 12234), ('would', 12027), ('even', 12008), ('good', 11926), ('my', 11766), ('only', 11566), ('their', 11317), ('no', 11271), ('really', 11064), ('had', 11041), ('which', 10896), ('can', 10793), ('up', 10775), ('were', 10528), ('see', 10409), ('than', 9807), ('we', 9415), ('-', 9355), ('been', 9074), ('into', 8990), ('get', 8958), ('will', 8926), ('story', 8739), ('much', 8738), ('because', 8735), ('most', 8475), ('how', 8456), ('other', 8228), ('also', 8006), ('first', 7984), ('its', 7963), ('time', 7943), ('do', 7903), (\"don't\", 7878), ('me', 7720), ('great', 7714), ('people', 7675), ('could', 7594), ('make', 7590), ('any', 7507), ('/>the', 7409), ('after', 7118), ('made', 7041), ('then', 6944), ('bad', 6816), ('think', 6772), ('being', 6390), ('many', 6388), ('him', 6383), ('never', 6319), ('two', 6210), ('too', 6140), ('little', 6121), ('where', 6056), ('well', 5847), ('way', 5812), ('<br', 5803), ('watch', 5709), ('your', 5599), ('it.', 5558), ('did', 5512), ('does', 5493), ('them', 5440), ('best', 5426), ('movie.', 5337), ('know', 5335), ('seen', 5332), ('love', 5326), ('characters', 5263), ('character', 5259), ('movies', 5254), ('these', 5233), ('ever', 5077), ('still', 5053), ('over', 5027), ('should', 4842), ('films', 4826), ('such', 4812), ('plot', 4776), ('acting', 4745), ('while', 4686), ('show', 4623), ('go', 4552), ('those', 4544), ('off', 4517), ('better', 4495), ('film.', 4490), ('through', 4454), (\"doesn't\", 4424), ('say', 4389), ('something', 4384), ('why', 4369), (\"i'm\", 4174), ('makes', 4150), (\"didn't\", 4147), ('watching', 4116), ('back', 4086), ('scene', 4059), ('film,', 4042), ('real', 4025), ('find', 4013), ('new', 3994), ('movie,', 3979), ('few', 3950), ('actually', 3911), ('every', 3885), ('scenes', 3872), ('man', 3870), ('life', 3865)]\n",
      "Size of naiveFrequency:  252192\n",
      "Example: the =  322174\n",
      "[('the', 156380), ('a', 77895), ('and', 71534), ('of', 68304), ('to', 68097), ('is', 48385), ('in', 42102), ('i', 37335), ('this', 37301), ('that', 33585), ('it', 32695), ('/><br', 26318), ('was', 25603), ('for', 21141), ('but', 20311), ('with', 20123), ('as', 19750), ('movie', 17370), ('on', 15784), ('not', 15170), ('have', 14980), ('are', 14251), ('you', 13942), ('be', 13916), ('film', 13135), ('his', 12015), ('at', 11829), ('he', 11817), ('they', 11644), ('one', 10809), ('like', 10458), ('just', 10352), ('by', 10253), ('an', 10109), ('so', 9979), ('all', 9745), ('or', 9559), ('from', 9435), ('who', 9025), ('if', 8600), ('about', 8579), ('some', 8072), (\"it's\", 8006), ('out', 7745), ('has', 7502), ('there', 7419), ('even', 7351), ('no', 7198), ('what', 7167), ('her', 7114), ('would', 6787), ('only', 6554), ('when', 6469), ('more', 6252), ('had', 6002), ('were', 5877), ('good', 5845), ('really', 5805), ('up', 5680), ('my', 5634), ('very', 5537), ('she', 5438), ('can', 5423), ('bad', 5335), ('their', 5252), ('which', 5145), ('than', 5127), ('see', 5010), ('been', 4993), ('get', 4850), ('because', 4803), (\"don't\", 4774), ('-', 4652), ('any', 4552), ('do', 4549), ('much', 4523), ('we', 4519), ('into', 4502), ('could', 4487), ('make', 4454), ('how', 4412), ('then', 4092), ('me', 4019), ('people', 4016), ('other', 3960), ('time', 3953), ('will', 3866), ('made', 3800), ('first', 3790), ('most', 3766), ('story', 3708), ('/>the', 3701), ('after', 3576), ('its', 3495), ('too', 3448), ('think', 3406), ('being', 3289), ('your', 3193), ('never', 3165), ('did', 3102), ('<br', 3095), ('movie.', 3089), ('also', 3032), ('where', 3020), ('plot', 3016), ('watch', 2963), ('little', 2950), ('acting', 2909), ('way', 2876), ('it.', 2876), ('know', 2841), ('two', 2826), ('them', 2818), ('should', 2815), ('why', 2815), ('ever', 2809), ('him', 2772), ('many', 2771), ('movies', 2740), ('characters', 2704), ('does', 2666), ('character', 2655), ('nothing', 2648), ('these', 2629), ('off', 2615), ('better', 2578), ('over', 2575), (\"doesn't\", 2526), (\"didn't\", 2523), (\"i'm\", 2519), ('seen', 2497), ('something', 2478), ('say', 2437), ('go', 2423), ('watching', 2409), ('such', 2392), ('actually', 2272), ('through', 2260), ('thing', 2251), ('worst', 2227), ('film.', 2218), ('great', 2210), ('movie,', 2194), ('going', 2169), ('films', 2147), ('while', 2141), ('those', 2121), ('scene', 2121), ('show', 2117), ('few', 2098), ('want', 2073), ('scenes', 2060), ('well', 2048), (\"can't\", 2037), ('pretty', 2032), ('still', 2030), ('&', 2011), ('/>i', 2009), ('look', 2008), ('seems', 1980)]\n",
      "Size of naiveFrequency_neg:  159177\n",
      "Example: the =  156380\n",
      "[('the', 165794), ('and', 87022), ('a', 82054), ('of', 76155), ('to', 65868), ('is', 55785), ('in', 48419), ('i', 33142), ('it', 32794), ('that', 32702), ('this', 32410), ('as', 25348), ('/><br', 24617), ('with', 22602), ('for', 21698), ('was', 21420), ('but', 19446), ('his', 17043), ('on', 15834), ('film', 14639), ('are', 14491), ('he', 14358), ('you', 13616), ('movie', 13513), ('not', 13421), ('have', 12363), ('be', 11774), ('by', 11721), ('one', 11668), ('an', 11130), ('at', 10901), ('from', 10498), ('who', 10382), ('all', 9993), ('her', 9424), ('has', 9068), ('they', 8979), ('like', 8321), ('so', 8116), ('very', 8096), (\"it's\", 7963), ('about', 7907), ('some', 7208), ('or', 7206), ('when', 7139), ('just', 6956), ('more', 6916), ('what', 6886), ('she', 6796), ('out', 6764), ('if', 6584), ('my', 6132), ('good', 6081), ('their', 6065), ('which', 5751), ('there', 5674), ('great', 5504), ('see', 5399), ('can', 5370), ('really', 5259), ('would', 5240), ('up', 5095), ('will', 5060), ('had', 5039), ('story', 5031), ('only', 5012), ('also', 4974), ('we', 4896), ('most', 4709), ('-', 4703), ('than', 4680), ('even', 4657), ('were', 4651), ('into', 4488), ('its', 4468), ('other', 4268), ('much', 4215), ('first', 4194), ('get', 4108), ('been', 4081), ('no', 4073), ('how', 4044), ('time', 3990), ('because', 3932), ('well', 3799), ('best', 3733), ('/>the', 3708), ('me', 3701), ('people', 3659), ('many', 3617), ('him', 3611), ('love', 3543), ('after', 3542), ('two', 3384), ('think', 3366), ('do', 3354), ('made', 3241), ('little', 3171), ('never', 3154), ('make', 3136), ('could', 3107), (\"don't\", 3104), ('being', 3101), ('where', 3036), ('still', 3023), ('any', 2955), ('way', 2936), ('then', 2852), ('seen', 2835), ('does', 2827), ('watch', 2746), ('<br', 2708), ('too', 2692), ('it.', 2682), ('films', 2679), ('them', 2622), ('these', 2604), ('character', 2604), ('characters', 2559), ('while', 2545), ('movies', 2514), ('show', 2506), ('know', 2494), ('life', 2471), ('over', 2452), ('those', 2423), ('such', 2420), ('did', 2410), ('your', 2406), ('makes', 2363), ('new', 2313), ('man', 2306), ('film.', 2272), ('ever', 2268), ('movie.', 2248), ('find', 2196), ('through', 2194), ('film,', 2189), ('back', 2178), ('real', 2146), ('go', 2129), ('young', 2126), ('quite', 2104), ('both', 2083), ('should', 2027), ('years', 2007), ('between', 1956), ('say', 1952), ('scene', 1938), ('may', 1918), ('better', 1917), ('every', 1915), ('always', 1911), ('something', 1906), ('lot', 1904), ('off', 1902), (\"doesn't\", 1898), ('few', 1852), ('us', 1839), ('acting', 1836)]\n",
      "Size of naiveFrequency_pos: 162004\n",
      "Example: the =  165794\n"
     ]
    }
   ],
   "source": [
    "# An example of naive word frequency\n",
    "print(naiveFrequency.most_common(160))\n",
    "print(\"Size of naiveFrequency: \", len(naiveFrequency))\n",
    "print(\"Example: the = \", naiveFrequency['the'])\n",
    "print(naiveFrequency_neg.most_common(160))\n",
    "print(\"Size of naiveFrequency_neg: \", len(naiveFrequency_neg))\n",
    "print(\"Example: the = \", naiveFrequency_neg['the'])\n",
    "print(naiveFrequency_pos.most_common(160))\n",
    "print(\"Size of naiveFrequency_pos:\", len(naiveFrequency_pos))\n",
    "print(\"Example: the = \", naiveFrequency_pos['the'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 0.3 - Word Frequency without Stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start counting naive word frequency: [=================== ] 99%\n",
      "Complete counting word frequency without stopword\n",
      "Start counting naive word frequency: [=================== ] 99%\n",
      "Complete counting word frequency without stopword\n",
      "Start counting naive word frequency: [=================== ] 99%\n",
      "Complete counting word frequency without stopword\n"
     ]
    }
   ],
   "source": [
    "# @author Pengnan Fan\n",
    "# @acknowledgement Yuxiang Ma, for this function is edited based on his in miniproject1\n",
    "# @param dataSet: set of comments\n",
    "# @return naiveCount: word frequency without stopwords\n",
    "def wordsFrequencyStopword(dataSet):\n",
    "    totalString = str()\n",
    "    count = 0\n",
    "    lenW = len(dataSet.data)\n",
    "    \n",
    "    for comment in dataSet.data: \n",
    "        totalString = totalString + ' ' + comment.decode(\"utf-8\").lower()\n",
    "        \n",
    "        # This is for loading bar\n",
    "        sys.stdout.write('\\r')\n",
    "        c = int((float(count) / float(lenW)) * 100)\n",
    "        sys.stdout.write(\"Start counting naive word frequency: [%-20s] %d%%\" % ('='*int(c / 5), c))\n",
    "        sleep(0.001)\n",
    "        sys.stdout.flush()\n",
    "        count += 1\n",
    "        \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    withoutPunc = tokenizer.tokenize(totalString)\n",
    "    stopwordsSet = set(stopwords.words())\n",
    "    \n",
    "    print(\"\\nComplete counting word frequency without stopword\")\n",
    "    \n",
    "    countDict = Counter(s.lower() for s in withoutPunc if s.lower() not in stopwordsSet)\n",
    "    return countDict\n",
    "\n",
    "stopwordFrequency = wordsFrequencyStopword(trainSet)\n",
    "stopwordFrequency_neg = wordsFrequencyStopword(trainSet_neg)\n",
    "stopwordFrequency_pos = wordsFrequencyStopword(trainSet_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('br', 101871), ('movie', 44047), ('film', 40159), ('one', 26795), ('like', 20281), ('good', 15147), ('time', 12727), ('even', 12655), ('would', 12436), ('story', 11988), ('really', 11738), ('see', 11479), ('well', 10667), ('much', 9764), ('get', 9311), ('bad', 9308), ('people', 9287), ('first', 9064), ('great', 9060), ('made', 8364), ('way', 8026), ('make', 8025), ('could', 7922), ('movies', 7668), ('think', 7297), ('characters', 7159), ('character', 7024), ('watch', 6974), ('two', 6906), ('films', 6889), ('seen', 6681), ('many', 6675), ('life', 6632), ('plot', 6589), ('acting', 6494), ('never', 6485), ('love', 6453), ('little', 6438), ('best', 6416), ('show', 6295), ('know', 6167), ('ever', 5992), ('better', 5740), ('still', 5624), ('say', 5396), ('scene', 5383), ('scenes', 5213), ('go', 5158), ('something', 5076), ('back', 4972), ('real', 4736), ('watching', 4606), ('though', 4566), ('old', 4526), ('thing', 4525), ('years', 4514), ('actors', 4488), ('director', 4449), ('work', 4374), ('10', 4351), ('another', 4330), ('new', 4311), ('nothing', 4291), ('funny', 4290), ('actually', 4240), ('makes', 4204), ('look', 4147), ('find', 4132), ('going', 4102), ('part', 4031), ('lot', 3980), ('every', 3978), ('world', 3835), ('cast', 3830), ('us', 3793), ('quite', 3739), ('things', 3688), ('pretty', 3664), ('young', 3660), ('seems', 3619), ('around', 3617), ('horror', 3591), ('got', 3587), ('however', 3537), ('fact', 3523), ('take', 3510), ('big', 3477), ('enough', 3453), ('long', 3452), ('thought', 3437), ('series', 3417), ('may', 3387), ('original', 3378), ('give', 3376), ('action', 3354), ('right', 3313), ('without', 3267), ('must', 3250), ('comedy', 3246), ('always', 3240), ('times', 3239), ('point', 3226), ('gets', 3204), ('family', 3202), ('role', 3189), ('saw', 3168), ('almost', 3140), ('interesting', 3129), ('least', 3113), ('done', 3096), ('whole', 3078), ('music', 3057), ('bit', 3054), ('guy', 3036), ('script', 3029), ('far', 2979), ('making', 2962), ('feel', 2951), ('anything', 2948), ('minutes', 2948), ('last', 2933), ('might', 2919), ('since', 2907), ('performance', 2898), ('2', 2896), ('girl', 2854), ('probably', 2842), ('woman', 2796), ('kind', 2783), ('tv', 2778), ('away', 2775), ('yet', 2754), ('day', 2746), ('rather', 2734), ('worst', 2731), ('fun', 2695), ('sure', 2686), ('hard', 2667), ('anyone', 2632), ('played', 2588), ('found', 2573), ('although', 2538), ('especially', 2536), ('course', 2506), ('believe', 2505), ('screen', 2493), ('comes', 2484), ('looking', 2483), ('trying', 2473), ('set', 2456), ('goes', 2442), ('book', 2421), ('looks', 2414), ('place', 2411), ('actor', 2389), ('different', 2385), ('put', 2381), ('money', 2363), ('year', 2360), ('ending', 2359)]\n",
      "Size of stopwordFrequency:  74266\n",
      "Example: br =  101871\n",
      "[('br', 52636), ('movie', 24969), ('film', 19219), ('one', 13138), ('like', 11241), ('even', 7691), ('good', 7423), ('bad', 7401), ('would', 7036), ('really', 6263), ('time', 6211), ('see', 5452), ('story', 5209), ('much', 5077), ('get', 5040), ('people', 4807), ('make', 4722), ('could', 4685), ('made', 4541), ('first', 4307), ('well', 4256), ('plot', 4155), ('movies', 4081), ('acting', 4056), ('way', 3989), ('think', 3642), ('characters', 3600), ('watch', 3550), ('character', 3508), ('better', 3358), ('know', 3334), ('seen', 3266), ('ever', 3264), ('never', 3259), ('two', 3173), ('little', 3096), ('films', 3076), ('nothing', 2990), ('say', 2982), ('something', 2942), ('many', 2909), ('thing', 2866), ('show', 2862), ('scene', 2816), ('scenes', 2785), ('go', 2718), ('great', 2641), ('watching', 2640), ('worst', 2479), ('actually', 2450), ('actors', 2441), ('life', 2429), ('back', 2424), ('director', 2408), ('funny', 2337), ('going', 2319), ('still', 2283), ('another', 2254), ('look', 2247), ('old', 2215), ('real', 2168), ('love', 2151), ('horror', 2150), ('minutes', 2123), ('pretty', 2115), ('best', 2096), ('though', 2091), ('script', 2075), ('work', 2028), ('10', 2027), ('every', 2024), ('seems', 2023), ('least', 2011), ('enough', 1998), ('original', 1984), ('guy', 1965), ('got', 1951), ('2', 1950), ('around', 1943), ('part', 1932), ('lot', 1892), ('anything', 1874), ('find', 1860), ('new', 1853), ('point', 1846), ('things', 1839), ('fact', 1839), ('give', 1823), ('makes', 1814), ('take', 1801), ('thought', 1798), ('whole', 1768), ('long', 1761), ('years', 1758), ('however', 1741), ('gets', 1714), ('cast', 1696), ('making', 1696), ('big', 1662), ('might', 1658), ('interesting', 1648), ('money', 1640), ('us', 1629), ('right', 1625), ('far', 1620), ('without', 1596), ('quite', 1596), ('almost', 1574), ('action', 1566), ('awful', 1557), ('kind', 1539), ('reason', 1535), ('looks', 1528), ('must', 1522), ('1', 1521), ('done', 1510), ('comedy', 1504), ('someone', 1491), ('trying', 1486), ('poor', 1481), ('boring', 1479), ('instead', 1479), ('saw', 1475), ('away', 1470), ('girl', 1464), ('probably', 1444), ('believe', 1434), ('sure', 1433), ('looking', 1430), ('stupid', 1428), ('anyone', 1418), ('times', 1406), ('world', 1405), ('maybe', 1404), ('rather', 1394), ('terrible', 1391), ('last', 1390), ('may', 1390), ('since', 1388), ('let', 1387), ('tv', 1379), ('hard', 1374), ('waste', 1359), ('woman', 1357), ('feel', 1354), ('effects', 1348), ('half', 1342), ('music', 1318), ('young', 1317), ('idea', 1312), ('sense', 1306), ('bit', 1298), ('book', 1278), ('3', 1267), ('found', 1267), ('series', 1264), ('put', 1263), ('goes', 1256), ('worse', 1249), ('said', 1230)]\n",
      "Size of stopwordFrequency_neg:  53772\n",
      "Example: movie =  24969\n",
      "[('br', 49235), ('film', 20940), ('movie', 19078), ('one', 13657), ('like', 9040), ('good', 7724), ('story', 6779), ('time', 6516), ('great', 6419), ('well', 6411), ('see', 6027), ('really', 5475), ('would', 5400), ('even', 4964), ('first', 4757), ('much', 4687), ('people', 4480), ('best', 4320), ('love', 4302), ('get', 4271), ('life', 4203), ('way', 4037), ('made', 3823), ('films', 3813), ('many', 3766), ('two', 3733), ('think', 3655), ('movies', 3587), ('characters', 3559), ('character', 3516), ('show', 3433), ('watch', 3424), ('seen', 3415), ('little', 3342), ('still', 3341), ('make', 3303), ('could', 3237), ('never', 3226), ('know', 2833), ('years', 2756), ('ever', 2728), ('real', 2568), ('scene', 2567), ('back', 2548), ('though', 2475), ('new', 2458), ('go', 2440), ('acting', 2438), ('plot', 2434), ('world', 2430), ('scenes', 2428), ('say', 2414), ('makes', 2390), ('better', 2382), ('work', 2346), ('young', 2343), ('10', 2324), ('old', 2311), ('find', 2272), ('us', 2164), ('series', 2153), ('quite', 2143), ('something', 2134), ('cast', 2134), ('part', 2099), ('always', 2089), ('lot', 2088), ('another', 2076), ('actors', 2047), ('director', 2041), ('family', 2032), ('may', 1997), ('role', 1967), ('watching', 1966), ('every', 1954), ('funny', 1953), ('performance', 1930), ('bad', 1907), ('look', 1900), ('things', 1849), ('times', 1833), ('big', 1815), ('however', 1796), ('actually', 1790), ('action', 1788), ('going', 1783), ('bit', 1756), ('comedy', 1742), ('music', 1739), ('must', 1728), ('take', 1709), ('saw', 1693), ('long', 1691), ('right', 1688), ('fun', 1688), ('fact', 1684), ('excellent', 1683), ('around', 1674), ('without', 1671), ('thing', 1659), ('thought', 1639), ('got', 1636), ('day', 1614), ('feel', 1597), ('seems', 1596), ('done', 1586), ('beautiful', 1582), ('especially', 1572), ('played', 1571), ('almost', 1566), ('yet', 1558), ('give', 1553), ('pretty', 1549), ('last', 1543), ('since', 1519), ('different', 1506), ('although', 1501), ('gets', 1490), ('true', 1487), ('interesting', 1481), ('job', 1470), ('enough', 1455), ('shows', 1448), ('horror', 1441), ('woman', 1439), ('tv', 1399), ('father', 1398), ('probably', 1398), ('original', 1394), ('girl', 1390), ('point', 1380), ('plays', 1378), ('wonderful', 1372), ('far', 1359), ('course', 1358), ('john', 1351), ('rather', 1340), ('dvd', 1324), ('later', 1324), ('whole', 1310), ('found', 1306), ('away', 1305), ('screen', 1305), ('nothing', 1301), ('year', 1297), ('hard', 1293), ('together', 1280), ('set', 1279), ('making', 1266), ('place', 1263), ('might', 1261), ('comes', 1260), ('sure', 1253), ('american', 1248), ('play', 1245), ('kind', 1244), ('takes', 1242), ('perfect', 1242), ('performances', 1238), ('worth', 1221)]\n",
      "Size of stopwordFrequency_pos:  55240\n",
      "Example: movie =  20940\n"
     ]
    }
   ],
   "source": [
    "# An example of word frequency without stopwords\n",
    "print(stopwordFrequency.most_common(160))\n",
    "print(\"Size of stopwordFrequency: \", len(stopwordFrequency))\n",
    "print(\"Example: br = \", stopwordFrequency['br'])\n",
    "print(stopwordFrequency_neg.most_common(160))\n",
    "print(\"Size of stopwordFrequency_neg: \", len(stopwordFrequency_neg))\n",
    "print(\"Example: movie = \", stopwordFrequency_neg['movie'])\n",
    "print(stopwordFrequency_pos.most_common(160))\n",
    "print(\"Size of stopwordFrequency_pos: \", len(stopwordFrequency_pos))\n",
    "print(\"Example: movie = \", stopwordFrequency_pos['film'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 0.4 - Number of Naive Existance of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start counting number of naive existance: [=================== ] 99%\n",
      "Complete counting number of naive existance\n",
      "Start counting number of naive existance: [=================== ] 99%\n",
      "Complete counting number of naive existance\n",
      "Start counting number of naive existance: [=================== ] 99%\n",
      "Complete counting number of naive existance\n"
     ]
    }
   ],
   "source": [
    "# @author Pengnan Fan\n",
    "# @param dataSet: set of comments\n",
    "# @return naiveCount: list of words of num of naive existances\n",
    "def numOfExistanceNaive(dataSet):\n",
    "    totalComments = []\n",
    "    count = 0\n",
    "    lenW = len(dataSet.data)\n",
    "    for comment in dataSet.data:\n",
    "        commentSplit = comment.decode(\"utf-8\").lower().split(\" \")\n",
    "        wordsToAdd = []\n",
    "        for word in commentSplit:\n",
    "            if word not in wordsToAdd:\n",
    "                wordsToAdd.append(word)\n",
    "        totalComments+=wordsToAdd\n",
    "        \n",
    "        # This is for loading bar\n",
    "        sys.stdout.write('\\r')\n",
    "        c = int((float(count) / float(lenW)) * 100)\n",
    "        sys.stdout.write(\"Start counting number of naive existance: [%-20s] %d%%\" % ('='*int(c / 5), c))\n",
    "        sleep(0.001)\n",
    "        sys.stdout.flush()\n",
    "        count += 1\n",
    "    \n",
    "    print(\"\\nComplete counting number of naive existance\")\n",
    "    \n",
    "    naiveCount = Counter(x for x in totalComments)\n",
    "    return naiveCount\n",
    "\n",
    "naiveNumOfExistance = numOfExistanceNaive(trainSet)\n",
    "naiveNumOfExistance_neg = numOfExistanceNaive(trainSet_neg)\n",
    "naiveNumOfExistance_pos = numOfExistanceNaive(trainSet_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 24771), ('a', 24143), ('and', 24072), ('of', 23705), ('to', 23440), ('is', 22312), ('this', 22248), ('in', 21885), ('it', 20248), ('that', 19723), ('i', 18615), ('for', 17650), ('but', 17354), ('with', 17231), ('was', 16042), ('as', 15859), ('on', 15141), ('/><br', 14665), ('not', 14361), ('have', 14079), ('be', 13777), ('are', 13744), ('movie', 13306), ('one', 12809), ('at', 12717), ('you', 12408), ('an', 12100), ('film', 11838), ('all', 11732), ('by', 11546), ('from', 11508), ('like', 11102), ('so', 10833), ('who', 10728), ('his', 10630), ('just', 10376), ('they', 10204), ('about', 10164), ('if', 9980), ('has', 9969), ('or', 9869), ('he', 9711), ('out', 9536), ('some', 9442), ('what', 9057), ('when', 8801), (\"it's\", 8785), ('there', 8600), ('very', 8551), ('more', 8551), ('only', 8184), ('good', 8171), ('even', 8114), ('would', 7944), ('my', 7728), ('can', 7673), ('see', 7517), ('no', 7510), ('up', 7494), ('really', 7358), ('had', 7332), ('than', 7062), ('which', 7030), ('their', 6958), ('were', 6659), ('get', 6562), ('been', 6537), ('much', 6494), ('into', 6365), ('most', 6341), ('other', 6214), ('story', 6179), ('will', 6111), ('her', 6106), ('because', 6105), ('how', 6072), ('time', 6063), (\"don't\", 5937), ('do', 5926), ('make', 5881), ('first', 5846), ('could', 5784), ('also', 5769), ('me', 5697), ('any', 5686), ('great', 5552), ('made', 5532), ('after', 5466), ('people', 5429), ('we', 5372), ('/>the', 5320), ('think', 5115), ('its', 5097), ('she', 5049), ('then', 4999), ('many', 4941), ('never', 4919), ('being', 4901), ('bad', 4745), ('it.', 4680), ('little', 4669), ('way', 4645), ('too', 4637), ('watch', 4595), ('two', 4581), ('well', 4579), ('where', 4567), ('seen', 4389), ('does', 4287), ('know', 4271), ('movie.', 4269), ('best', 4246), ('did', 4245), ('your', 4212), ('ever', 4206), ('them', 4130), ('acting', 4123), ('him', 4087), ('characters', 4052), ('still', 4021), ('movies', 4001), ('these', 3983), ('over', 3949), ('should', 3946), ('love', 3901), ('character', 3900), ('plot', 3886), ('-', 3817), ('such', 3801), ('go', 3772), ('better', 3759), ('while', 3696), ('film.', 3682), ('those', 3671), ('off', 3666), ('through', 3634), ('say', 3624), ('something', 3593), (\"doesn't\", 3547), ('films', 3527), ('makes', 3502), ('<br', 3473), ('watching', 3471), ('few', 3344), ('why', 3342), ('back', 3332), (\"didn't\", 3329), ('find', 3305), (\"i'm\", 3297), ('real', 3284), ('movie,', 3245), ('film,', 3245), ('every', 3240), ('actually', 3202), ('going', 3180), ('another', 3143), ('same', 3129), ('nothing', 3127), ('/>i', 3120), ('look', 3119)]\n",
      "Size of naiveNumOfExistance:  252192\n",
      "Example: the =  24771\n",
      "[('the', 12402), ('a', 12087), ('and', 11959), ('of', 11859), ('to', 11839), ('this', 11345), ('is', 11007), ('in', 10850), ('it', 10167), ('that', 10045), ('i', 9715), ('but', 8906), ('for', 8860), ('with', 8481), ('was', 8476), ('on', 7674), ('as', 7567), ('not', 7561), ('/><br', 7509), ('have', 7483), ('be', 7295), ('movie', 7249), ('are', 6774), ('at', 6599), ('you', 6393), ('one', 6280), ('like', 6007), ('an', 5903), ('so', 5872), ('just', 5850), ('all', 5845), ('film', 5717), ('from', 5657), ('by', 5647), ('they', 5595), ('if', 5489), ('or', 5463), ('about', 5273), ('who', 5139), ('out', 5038), ('some', 4968), ('his', 4904), ('even', 4793), ('there', 4755), ('what', 4710), ('has', 4699), ('he', 4634), ('no', 4582), ('only', 4560), (\"it's\", 4465), ('would', 4375), ('when', 4264), ('more', 4170), ('good', 4094), ('had', 3990), ('up', 3935), ('can', 3879), ('really', 3868), ('my', 3795), ('very', 3719), ('than', 3715), ('were', 3699), ('see', 3660), ('been', 3594), ('bad', 3533), (\"don't\", 3530), ('get', 3501), ('which', 3441), ('much', 3408), ('make', 3379), ('could', 3372), ('their', 3370), ('any', 3358), ('because', 3351), ('do', 3348), ('into', 3201), ('how', 3196), ('time', 3067), ('other', 3032), ('me', 3012), ('made', 2955), ('most', 2918), ('her', 2888), ('then', 2854), ('people', 2833), ('first', 2796), ('after', 2790), ('story', 2721), ('will', 2708), ('/>the', 2640), ('think', 2635), ('we', 2628), ('too', 2541), ('being', 2513), ('acting', 2502), ('plot', 2440), ('movie.', 2437), ('never', 2433), ('she', 2432), ('it.', 2405), ('your', 2389), ('watch', 2380), ('did', 2357), ('where', 2313), ('its', 2303), ('way', 2300), ('ever', 2293), ('also', 2286), ('little', 2270), ('should', 2255), ('know', 2239), ('many', 2189), ('better', 2155), ('nothing', 2152), ('two', 2147), ('them', 2139), ('does', 2099), ('off', 2098), ('movies', 2095), ('seen', 2082), ('characters', 2078), ('why', 2050), ('something', 2032), ('watching', 2025), ('say', 2019), ('over', 2010), ('these', 2002), (\"didn't\", 1998), ('go', 1997), (\"doesn't\", 1982), ('-', 1965), (\"i'm\", 1964), ('character', 1955), ('such', 1919), ('thing', 1917), ('through', 1883), ('worst', 1878), ('him', 1859), ('actually', 1853), ('<br', 1824), ('film.', 1820), ('great', 1793), ('going', 1793), ('movie,', 1773), ('want', 1751), ('few', 1749), (\"can't\", 1744), ('well', 1731), ('those', 1730), ('while', 1724), ('still', 1695), ('look', 1687), ('/>i', 1663), ('another', 1651), ('every', 1643), ('pretty', 1629), ('scenes', 1626), ('end', 1611), ('got', 1609), ('same', 1605)]\n",
      "Size of naiveNumOfExistance_neg:  159177\n",
      "Example: the =  12402\n",
      "[('the', 12369), ('and', 12113), ('a', 12056), ('of', 11846), ('to', 11601), ('is', 11305), ('in', 11035), ('this', 10903), ('it', 10081), ('that', 9678), ('i', 8900), ('for', 8790), ('with', 8750), ('but', 8448), ('as', 8292), ('was', 7566), ('on', 7467), ('/><br', 7156), ('are', 6970), ('not', 6800), ('have', 6596), ('one', 6529), ('be', 6482), ('an', 6197), ('film', 6121), ('at', 6118), ('movie', 6057), ('you', 6015), ('by', 5899), ('all', 5887), ('from', 5851), ('his', 5726), ('who', 5589), ('has', 5270), ('like', 5095), ('he', 5077), ('so', 4961), ('about', 4891), ('very', 4832), ('they', 4609), ('when', 4537), ('just', 4526), ('out', 4498), ('if', 4491), ('some', 4474), ('or', 4406), ('more', 4381), ('what', 4347), (\"it's\", 4320), ('good', 4077), ('my', 3933), ('see', 3857), ('there', 3845), ('can', 3794), ('great', 3759), ('only', 3624), ('which', 3589), ('their', 3588), ('would', 3569), ('up', 3559), ('really', 3490), ('also', 3483), ('story', 3458), ('most', 3423), ('will', 3403), ('than', 3347), ('had', 3342), ('even', 3321), ('her', 3218), ('other', 3182), ('into', 3164), ('much', 3086), ('get', 3061), ('first', 3050), ('time', 2996), ('were', 2960), ('been', 2943), ('no', 2928), ('how', 2876), ('well', 2848), ('best', 2808), ('its', 2794), ('because', 2754), ('many', 2752), ('we', 2744), ('me', 2685), ('/>the', 2680), ('after', 2676), ('she', 2617), ('people', 2596), ('do', 2578), ('made', 2577), ('make', 2502), ('never', 2486), ('love', 2482), ('think', 2480), ('two', 2434), ('could', 2412), (\"don't\", 2407), ('little', 2399), ('being', 2388), ('way', 2345), ('any', 2328), ('still', 2326), ('seen', 2307), ('it.', 2275), ('where', 2254), ('him', 2228), ('watch', 2215), ('does', 2188), ('then', 2145), ('too', 2096), ('know', 2032), ('them', 1991), ('these', 1981), ('characters', 1974), ('while', 1972), ('makes', 1960), ('character', 1945), ('films', 1944), ('those', 1941), ('over', 1939), ('ever', 1913), ('movies', 1906), ('did', 1888), ('such', 1882), ('film.', 1862), ('-', 1852), ('movie.', 1832), ('your', 1823), ('life', 1807), ('go', 1775), ('find', 1774), ('back', 1762), ('through', 1751), ('film,', 1750), ('new', 1740), ('real', 1713), ('should', 1691), ('years', 1682), ('quite', 1668), ('<br', 1649), ('man', 1649), ('both', 1627), ('acting', 1621), ('say', 1605), ('better', 1604), ('every', 1597), ('few', 1595), ('young', 1573), ('always', 1572), ('off', 1568), (\"doesn't\", 1565), ('lot', 1562), ('something', 1561), ('between', 1533), ('same', 1524), ('may', 1498), ('another', 1492), ('show', 1487)]\n",
      "Size of naiveNumOfExistance_pos:  162004\n",
      "Example: the =  12369\n"
     ]
    }
   ],
   "source": [
    "# An example of number of naive existance of words\n",
    "print(naiveNumOfExistance.most_common(160))\n",
    "print(\"Size of naiveNumOfExistance: \", len(naiveNumOfExistance))\n",
    "print(\"Example: the = \", naiveNumOfExistance['the'])\n",
    "print(naiveNumOfExistance_neg.most_common(160))\n",
    "print(\"Size of naiveNumOfExistance_neg: \", len(naiveNumOfExistance_neg))\n",
    "print(\"Example: the = \", naiveNumOfExistance_neg['the'])\n",
    "print(naiveNumOfExistance_pos.most_common(160))\n",
    "print(\"Size of naiveNumOfExistance_pos: \", len(naiveNumOfExistance_pos))\n",
    "print(\"Example: the = \", naiveNumOfExistance_pos['the'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 0.5 - Number of Existance of Words without Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start counting number of existance without stopwords: [===                 ] 17%"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-a8b0ba289f22>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcountDict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mstopwordNumOfExistance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumOfExistanceStopword\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[0mstopwordNumOfExistance_neg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumOfExistanceStopword\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainSet_neg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mstopwordNumOfExistance_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumOfExistanceStopword\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainSet_pos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-a8b0ba289f22>\u001b[0m in \u001b[0;36mnumOfExistanceStopword\u001b[1;34m(dataSet)\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[0mwordsToAdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwordsToAdd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mtotalString\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotalString\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# This is for loading bar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# @author Pengnan Fan\n",
    "# @param dataSet: set of comments\n",
    "# @return naiveCount: list of num of existances of words without stopwords\n",
    "def numOfExistanceStopword(dataSet):\n",
    "    totalString = str()\n",
    "    count = 0\n",
    "    lenW = len(dataSet.data)\n",
    "    \n",
    "    for comment in dataSet.data: \n",
    "        commentSplit = comment.decode(\"utf-8\").lower().split(\" \")\n",
    "        wordsToAdd = []\n",
    "        for word in commentSplit:\n",
    "            if word not in wordsToAdd:\n",
    "                wordsToAdd.append(word)\n",
    "        for word in wordsToAdd:\n",
    "            totalString = totalString + ' ' + word\n",
    "        \n",
    "        # This is for loading bar\n",
    "        sys.stdout.write('\\r')\n",
    "        c = int((float(count) / float(lenW)) * 100)\n",
    "        sys.stdout.write(\"Start counting number of existance without stopwords: [%-20s] %d%%\" % ('='*int(c / 5), c))\n",
    "        sleep(0.001)\n",
    "        sys.stdout.flush()\n",
    "        count += 1\n",
    "        \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    withoutPunc = tokenizer.tokenize(totalString)\n",
    "    stopwordsSet = set(stopwords.words())\n",
    "    \n",
    "    print(\"\\nComplete counting number of naive existance without stopwords\")\n",
    "    \n",
    "    countDict = Counter(s.lower() for s in withoutPunc if s.lower() not in stopwordsSet)\n",
    "    return countDict\n",
    "\n",
    "stopwordNumOfExistance = numOfExistanceStopword(trainSet)\n",
    "stopwordNumOfExistance_neg = numOfExistanceStopword(trainSet_neg)\n",
    "stopwordNumOfExistance_pos = numOfExistanceStopword(trainSet_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example of number of existance of words without stopwords\n",
    "print(stopwordNumOfExistance.most_common(160))\n",
    "print(\"Size of stopwordNumOfExistance: \", len(stopwordNumOfExistance))\n",
    "print(\"Example: br = \", stopwordNumOfExistance['br'])\n",
    "print(naiveNumOfExistance_neg.most_common(160))\n",
    "print(\"Size of stopwordNumOfExistance_neg: \", len(stopwordNumOfExistance_neg))\n",
    "print(\"Example: movie = \", stopwordNumOfExistance_neg['movie'])\n",
    "print(naiveNumOfExistance_pos.most_common(160))\n",
    "print(\"Size of stopwordNumOfExistance_pos: \", len(stopwordNumOfExistance_pos))\n",
    "print(\"Example: movie = \", stopwordNumOfExistance_pos['film'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @author Pengnan Fan\n",
    "# @param dataSet: set for prediction\n",
    "# @param totalWordFreq: word frequency of both neg and pos set\n",
    "# @param negWordFreq: word frequency of neg set\n",
    "# @param posWordFreq: word frequency of pos set\n",
    "# @param numOfExamples: list {0 -> all, 1 -> pos, 2 -> neg}\n",
    "# @return prediction\n",
    "def bernoulliNaiveBayes(dataSet, totalWordFreq, negWordFreq, posWordFreq, numOfExamples):\n",
    "    for comment in dataSet.data:\n",
    "        word = comment.decode(\"utf-8\").lower().split\n",
    "        existanceAndPos = 1\n",
    "        existanceAndNeg = 1\n",
    "        for w in word:\n",
    "            existanceAndPos+=posWordFreq[word]\n",
    "            existanceAndNeg+=negWordFreq[word]\n",
    "        probPos = (existanceAndPos+1)/(numOfExamples[1]+2)\n",
    "        probNeg = (existanceAndNeg+1)/(numOfExamples[2]+2)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
