{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP551 Mini Project 2 - IMDB Sentiment Analysis  \n",
    "This is the codes of mini project2 - IMDB Sentiment Analysis.  \n",
    "\n",
    "## AUTHORS\n",
    "Pengnan Fan, ID#260768510  \n",
    "\n",
    "## TASKS\n",
    "1. **Bernoulli Naive Bayes** (w/o any external library).  \n",
    "2. **At least 2** out of 3 classifiers from the SciKit. i.e. suggestions: logistic regression, decision tree, or support vector machines  \n",
    "3. **At least 2** different features extraction pipelines for processing the data.  \n",
    "4. A model validation. i.e. **K-fold cross validation**  \n",
    "\n",
    "## UPDATES\n",
    "**<January 6, 2019>** Pengnan Fan create this notebook and implements functions readTrainData and readTestData  \n",
    "> * **readTrainData(address:String):DataFrame**  \n",
    "> This function takes a string **address** which indicates the address of your train data and will load comments and isPositive to a DataFrame.\n",
    "> * **readTestData(address:String):DataFrame**  \n",
    "> This function takes a string **address** which indicates the address of your test data and will load comments and isPositive to a DataFrame. **Note: all isPositive is initialized as 0**  \n",
    "> * **Learning set** 25000 in total\n",
    "> * **Test set** 25000 in total  \n",
    "\n",
    "**<January 7, 2019>** Pengnan Fan implements wordsFrequencyNaive and wordsFrequencyStopword\n",
    "> * **wordsFrequencyNaive(dataSet:DataFrame)**  \n",
    "> This function takes a DataFrame **dataSet** and calculate the naive word frequency  \n",
    "> * **wordsFrequencyStopword(dataSet:DataFrame)**  \n",
    "> This function takes a DataFrame **dataSet** and calculate the word frequency without stopwords  \n",
    "\n",
    "**<January 9, 2019>** Pengnan Fan uses sklearn.datasets.load_files(address:str) to load all datas. It helps to increase the speed of loading.  \n",
    "> * **sklearn.datasets.load_files** - [Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_files.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import sys\n",
    "from time import sleep\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "import numpy\n",
    "import scipy\n",
    "import sklearn.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0 - Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading train set\n",
      "Complete loading train set\n",
      "Start loading test set\n",
      "Complete loading test set\n"
     ]
    }
   ],
   "source": [
    "# Task 0 - Preprocessing Data\n",
    "\n",
    "# Please add your address here as string\n",
    "ADDRESS_TRAIN_PENGNAN = \"D:\\\\McGill\\\\19Fall\\\\COMP 551\\\\Projects\\\\Project2\\\\comp-551-imbd-sentiment-classification\\\\train\"\n",
    "ADDRESS_TEST_PENGNAN = \"D:\\\\McGill\\\\19Fall\\\\COMP 551\\\\Projects\\\\Project2\\\\comp-551-imbd-sentiment-classification\\\\test\"\n",
    "\n",
    "'''\n",
    "# @author Pengnan Fan\n",
    "# @param address: address of your train data file as string\n",
    "# @return output: DataFrame{'comment':comments, 'isPositive':[0,1]}\n",
    "def readTrainData(address):\n",
    "    \n",
    "    print(\"Start reading learning set\")\n",
    "    # Read negative data as DataFrame\n",
    "    comment = []\n",
    "    isPositive = []\n",
    "    allNegFiles = glob.glob(address+\"\\\\neg\" + \"/*.txt\")\n",
    "    count = 0\n",
    "    lenN = len(allNegFiles)\n",
    "    for file in allNegFiles:\n",
    "        comment.append(pd.read_csv(file, quotechar=None, quoting=3, delimiter='\\r').columns[0])\n",
    "        isPositive.append(0)\n",
    "        \n",
    "        # This is for loading bar\n",
    "        sys.stdout.write('\\r')\n",
    "        c = int((float(count) / float(lenN)) * 100)\n",
    "        sys.stdout.write(\"Start reading negative comments: [%-20s] %d%%\" % ('='*int(c / 5), c))\n",
    "        sleep(0.001)\n",
    "        sys.stdout.flush()\n",
    "        count += 1\n",
    "        \n",
    "    print(\"\\nComplete reading negative comments\")\n",
    "    \n",
    "    # Read positive data as DataFrame\n",
    "    allPosFiles = glob.glob(address+\"\\\\pos\" + \"/*.txt\")\n",
    "    count = 0\n",
    "    lenP = len(allPosFiles)\n",
    "    for file in allPosFiles:\n",
    "        comment.append(pd.read_csv(file, quotechar=None, quoting=3, delimiter='\\r').columns[0])\n",
    "        isPositive.append(1)\n",
    "        \n",
    "        # This is for loading bar\n",
    "        c = int((float(count) / float(lenP)) * 100)\n",
    "        sys.stdout.write('\\r')\n",
    "        sys.stdout.write(\"Start reading positive comments: [%-20s] %d%%\" % ('='*int(c / 5), c))\n",
    "        sleep(0.001)\n",
    "        sys.stdout.flush()\n",
    "        count += 1\n",
    "        \n",
    "    print(\"\\nComplete reading postive comments\")\n",
    "    print(\"Complete reading learning set\\n\")\n",
    "    \n",
    "    output = pd.DataFrame({'comment':comment, 'isPositive':isPositive})\n",
    "    return output\n",
    "\n",
    "# @author Pengnan Fan\n",
    "# @param address: address of your test data file as string\n",
    "# @return output: DataFrame{'comment':comments, 'isPositive':[0,1]}\n",
    "# Note: all isPositive is initialized as 0\n",
    "def readTestData(address):\n",
    "    \n",
    "    # Read negative data as DataFrame\n",
    "    comment = []\n",
    "    isPositive = []\n",
    "    allFiles = glob.glob(address+\"/*.txt\")\n",
    "    count = 0\n",
    "    lenN = len(allFiles)\n",
    "    for file in allFiles:\n",
    "        comment.append(pd.read_csv(file, quotechar=None, quoting=3, delimiter='\\r').columns[0])\n",
    "        isPositive.append(0)\n",
    "        \n",
    "        # This is for loading bar\n",
    "        sys.stdout.write('\\r')\n",
    "        c = int((float(count) / float(lenN)) * 100)\n",
    "        sys.stdout.write(\"Start reading test set: [%-20s] %d%%\" % ('='*int(c / 5), c))\n",
    "        sleep(0.001)\n",
    "        sys.stdout.flush()\n",
    "        count += 1\n",
    "        \n",
    "    print(\"\\nComplete reading test set\")\n",
    "    \n",
    "    output = pd.DataFrame({'comment':comment, 'isPositive':isPositive})\n",
    "    return output\n",
    "\n",
    "learningSet = readTrainData(ADDRESS_TRAIN_PENGNAN)\n",
    "testSet = readTestData(ADDRESS_TEST_PENGNAN)\n",
    "'''\n",
    "\n",
    "# Advanced loader\n",
    "# @return: Bunch\n",
    "print(\"Start loading train set\")\n",
    "trainSet = sklearn.datasets.load_files(ADDRESS_TRAIN_PENGNAN)\n",
    "print(\"Complete loading train set\")\n",
    "print(\"Start loading test set\")\n",
    "testSet = sklearn.datasets.load_files(ADDRESS_TEST_PENGNAN)\n",
    "print(\"Complete loading test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data set has a structure of:\n",
      "data :  <class 'str'>\n",
      "filenames :  <class 'str'>\n",
      "target_names :  <class 'str'>\n",
      "target :  <class 'str'>\n",
      "DESCR :  <class 'str'>\n",
      "Here are some examples:\n",
      "data:  Zero Day leads you to think, even re-think why two boys/young men would do what they did - commit mutual suicide via slaughtering their classmates. It captures what must be beyond a bizarre mode of being for two humans who have decided to withdraw from common civility in order to define their own/mutual world via coupled destruction.<br /><br />It is not a perfect movie but given what money/time the filmmaker and actors had - it is a remarkable product. In terms of explaining the motives and actions of the two young suicide/murderers it is better than 'Elephant' - in terms of being a film that gets under our 'rationalistic' skin it is a far, far better film than almost anything you are likely to see. <br /><br />Flawed but honest with a terrible honesty.\n",
      "target_names:  neg\n",
      "The rest are irrelevent to this project.\n",
      "NOTE: Type \"data\" is in Byte mode. You need to transform them into string by using .decode(\"utf-8\")\n"
     ]
    }
   ],
   "source": [
    "# An example of the dataset\n",
    "'''\n",
    "print(\"The first learning set comment is:\\n\", learningSet['comment'][0],'\\nisPositive: ', learningSet['isPositive'][0])\n",
    "print(\"The total size of learning set: \", len(learningSet.comment))\n",
    "print(\"The first test comment is:\\n\", testSet['comment'][0])\n",
    "print(\"The total size of test set: \", len(testSet.comment))\n",
    "'''\n",
    "print(\"The data set has a structure of:\")\n",
    "for dataPoint in trainSet:\n",
    "    print(dataPoint,\": \", type(dataPoint))\n",
    "print(\"Here are some examples:\")\n",
    "print(\"data: \", trainSet.data[0].decode(\"utf-8\"))\n",
    "print(\"target_names: \", trainSet.target_names[0])\n",
    "print(\"The rest are irrelevent to this project.\\nNOTE: Type \\\"data\\\" is in Byte mode. You need to transform them into string by using .decode(\\\"utf-8\\\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start counting naive word frequency: [=================== ] 99%\n",
      "Complete counting naive word frequency\n"
     ]
    }
   ],
   "source": [
    "# @author Pengnan Fan\n",
    "# @param dataSet: set of comments\n",
    "# @return naiveCount: naive word frequency\n",
    "def wordsFrequencyNaive(dataSet):\n",
    "    totalComments = []\n",
    "    count = 0\n",
    "    lenW = len(dataSet.data)\n",
    "    for comment in dataSet.data:\n",
    "        totalComments+=comment.decode(\"utf-8\").lower().split(\" \")\n",
    "        \n",
    "        # This is for loading bar\n",
    "        sys.stdout.write('\\r')\n",
    "        c = int((float(count) / float(lenW)) * 100)\n",
    "        sys.stdout.write(\"Start counting naive word frequency: [%-20s] %d%%\" % ('='*int(c / 5), c))\n",
    "        sleep(0.001)\n",
    "        sys.stdout.flush()\n",
    "        count += 1\n",
    "    \n",
    "    print(\"\\nComplete counting naive word frequency\")\n",
    "    \n",
    "    naiveCount = Counter(x for x in totalComments)\n",
    "    return naiveCount\n",
    "\n",
    "naiveFrequency = wordsFrequencyNaive(learningSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 322174), ('a', 159949), ('and', 158556), ('of', 144459), ('to', 133965), ('is', 104170), ('in', 90521), ('i', 70477), ('this', 69711), ('that', 66287), ('it', 65489), ('/><br', 50935), ('was', 47023), ('as', 45098), ('for', 42839), ('with', 42725), ('but', 39757), ('on', 31618), ('movie', 30883), ('his', 29058), ('are', 28742), ('not', 28591), ('film', 27774), ('you', 27558), ('have', 27343), ('he', 26175), ('be', 25690), ('at', 22730), ('one', 22477), ('by', 21974), ('an', 21239), ('they', 20623), ('from', 19933), ('all', 19738), ('who', 19407), ('like', 18779), ('so', 18095), ('just', 17308), ('or', 16765), ('has', 16570), ('her', 16538), ('about', 16486), (\"it's\", 15969), ('some', 15280), ('if', 15184), ('out', 14509), ('what', 14053), ('very', 13633), ('when', 13608), ('more', 13168), ('there', 13093), ('she', 12234), ('would', 12027), ('even', 12008), ('good', 11926), ('my', 11766), ('only', 11566), ('their', 11317), ('no', 11271), ('really', 11064), ('had', 11041), ('which', 10896), ('can', 10793), ('up', 10775), ('were', 10528), ('see', 10409), ('than', 9807), ('we', 9415), ('-', 9355), ('been', 9074), ('into', 8990), ('get', 8958), ('will', 8926), ('story', 8739), ('much', 8738), ('because', 8735), ('most', 8475), ('how', 8456), ('other', 8228), ('also', 8006), ('first', 7984), ('its', 7963), ('time', 7943), ('do', 7903), (\"don't\", 7878), ('me', 7720), ('great', 7714), ('people', 7675), ('could', 7594), ('make', 7590), ('any', 7507), ('/>the', 7409), ('after', 7118), ('made', 7041), ('then', 6944), ('bad', 6816), ('think', 6772), ('being', 6390), ('many', 6388), ('him', 6383), ('never', 6319), ('two', 6210), ('too', 6140), ('little', 6121), ('where', 6056), ('well', 5847), ('way', 5812), ('<br', 5803), ('watch', 5709), ('your', 5599), ('it.', 5558), ('did', 5512), ('does', 5493), ('them', 5440), ('best', 5426), ('movie.', 5337), ('know', 5335), ('seen', 5332), ('love', 5326), ('characters', 5263), ('character', 5259), ('movies', 5254), ('these', 5233), ('ever', 5077), ('still', 5053), ('over', 5027), ('should', 4842), ('films', 4826), ('such', 4812), ('plot', 4776), ('acting', 4745), ('while', 4686), ('show', 4623), ('go', 4552), ('those', 4544), ('off', 4517), ('better', 4495), ('film.', 4490), ('through', 4454), (\"doesn't\", 4424), ('say', 4389), ('something', 4384), ('why', 4369), (\"i'm\", 4174), ('makes', 4150), (\"didn't\", 4147), ('watching', 4116), ('back', 4086), ('scene', 4059), ('film,', 4042), ('real', 4025), ('find', 4013), ('new', 3994), ('movie,', 3979), ('few', 3950), ('actually', 3911), ('every', 3885), ('scenes', 3872), ('man', 3870), ('life', 3865)]\n",
      "Size of naiveFrequency:  252192\n"
     ]
    }
   ],
   "source": [
    "# An example of naive word frequency\n",
    "print(naiveFrequency.most_common(160))\n",
    "print(\"Size of naiveFrequency: \", len(naiveFrequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start counting naive word frequency: [=================== ] 99%\n",
      "Complete counting word frequency without stopword\n"
     ]
    }
   ],
   "source": [
    "# @author Pengnan Fan\n",
    "# @acknowledgement Yuxiang Ma, for this function is edited based on his in miniproject1\n",
    "# @param dataSet: set of comments\n",
    "# @return naiveCount: word frequency without stopwords\n",
    "def wordsFrequencyStopword(dataSet):\n",
    "    totalString = str()\n",
    "    count = 0\n",
    "    lenW = len(dataSet.data)\n",
    "    \n",
    "    for comment in dataSet.data: \n",
    "        totalString = totalString + ' ' + comment.decode(\"utf-8\").lower()\n",
    "        \n",
    "        # This is for loading bar\n",
    "        sys.stdout.write('\\r')\n",
    "        c = int((float(count) / float(lenW)) * 100)\n",
    "        sys.stdout.write(\"Start counting naive word frequency: [%-20s] %d%%\" % ('='*int(c / 5), c))\n",
    "        sleep(0.001)\n",
    "        sys.stdout.flush()\n",
    "        count += 1\n",
    "        \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    withoutPunc = tokenizer.tokenize(totalString)\n",
    "    stopwordsSet = set(stopwords.words())\n",
    "    \n",
    "    print(\"\\nComplete counting word frequency without stopword\")\n",
    "    \n",
    "    countDict = Counter(s.lower() for s in withoutPunc if s.lower() not in stopwordsSet)\n",
    "    return countDict\n",
    "\n",
    "stopwordFrequency = wordsFrequencyStopword(learningSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('br', 101871), ('movie', 44047), ('film', 40159), ('one', 26795), ('like', 20281), ('good', 15147), ('time', 12727), ('even', 12655), ('would', 12436), ('story', 11988), ('really', 11738), ('see', 11479), ('well', 10667), ('much', 9764), ('get', 9311), ('bad', 9308), ('people', 9287), ('first', 9064), ('great', 9060), ('made', 8364), ('way', 8026), ('make', 8025), ('could', 7922), ('movies', 7668), ('think', 7297), ('characters', 7159), ('character', 7024), ('watch', 6974), ('two', 6906), ('films', 6889), ('seen', 6681), ('many', 6675), ('life', 6632), ('plot', 6589), ('acting', 6494), ('never', 6485), ('love', 6453), ('little', 6438), ('best', 6416), ('show', 6295), ('know', 6167), ('ever', 5992), ('better', 5740), ('still', 5624), ('say', 5396), ('scene', 5383), ('scenes', 5213), ('go', 5158), ('something', 5076), ('back', 4972), ('real', 4736), ('watching', 4606), ('though', 4566), ('old', 4526), ('thing', 4525), ('years', 4514), ('actors', 4488), ('director', 4449), ('work', 4374), ('10', 4351), ('another', 4330), ('new', 4311), ('nothing', 4291), ('funny', 4290), ('actually', 4240), ('makes', 4204), ('look', 4147), ('find', 4132), ('going', 4102), ('part', 4031), ('lot', 3980), ('every', 3978), ('world', 3835), ('cast', 3830), ('us', 3793), ('quite', 3739), ('things', 3688), ('pretty', 3664), ('young', 3660), ('seems', 3619), ('around', 3617), ('horror', 3591), ('got', 3587), ('however', 3537), ('fact', 3523), ('take', 3510), ('big', 3477), ('enough', 3453), ('long', 3452), ('thought', 3437), ('series', 3417), ('may', 3387), ('original', 3378), ('give', 3376), ('action', 3354), ('right', 3313), ('without', 3267), ('must', 3250), ('comedy', 3246), ('always', 3240)]\n",
      "Size of stopwordFrequency:  74266\n"
     ]
    }
   ],
   "source": [
    "# An example of word frequency without stopwords\n",
    "print(stopwordFrequency.most_common(100))\n",
    "print(\"Size of stopwordFrequency: \", len(stopwordFrequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency with condition of positivity and negativity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
